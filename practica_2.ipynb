{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5318478e-c2e9-49ab-a66d-ad6d3a8f6486",
   "metadata": {},
   "source": [
    "## Practica 2\n",
    "\n",
    "### Ejercicio 1)\n",
    "¿En el dataset del ejercicio 1 de la práctica 1 indique para cada Job, si se vería beneficiado por una función combiner?\n",
    "En caso afirmativo, ¿cuál es la implementación de dicha función? ¿Qué datos recibe cada reduce, al utilizar la función combiner?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ca962-7047-420f-aa38-ada70ee73fb0",
   "metadata": {},
   "source": [
    "### 2) Implemente una función combiner para el problema del WordCount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862c096a-e224-4355-a583-e3a60a91c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MRE] Iniciando etapa de mapeo...\n",
      "[Map] EL -> 1\n",
      "[Map] AMO -> 1\n",
      "[Map] VIEJO -> 1\n",
      "[Map] Nos -> 1\n",
      "[Map] apeamos -> 1\n",
      "[Map] de -> 1\n",
      "[Map] nuestras -> 1\n",
      "[Map] caballerías -> 1\n",
      "[Map] en -> 1\n",
      "[Map] un -> 1\n",
      "... [más resultados de map omitidos]\n",
      "[MRE] Iniciando etapa de reducción...\n",
      "[Reduce] Clave recibida: !ah!\n",
      "[Reduce] Clave recibida: \"A\"\n",
      "[Reduce] Clave recibida: \"B\"\n",
      "[Reduce] Clave recibida: \"Dr.\n",
      "[Reduce] Clave recibida: \"El\n",
      "[Reduce] Clave recibida: \"purgar\",\n",
      "[Reduce] Clave recibida: (aquÃ­\n",
      "[Reduce] Clave recibida: (con\n",
      "[Reduce] Clave recibida: (naturalmente)\n",
      "[Reduce] Clave recibida: *\n",
      "... [más reduce claves omitidas]\n",
      "[MRE] Finalizando y escribiendo resultados en disco...\n",
      "\n",
      "[MRE] Resultados finales del Job:\n",
      "!ah!\t1\n",
      "\"A\"\t1\n",
      "\"B\"\t1\n",
      "\"Dr.\t1\n",
      "\"El\t1\n",
      "\"purgar\",\t1\n",
      "(aquÃ­\t1\n",
      "(con\t1\n",
      "(naturalmente)\t1\n",
      "*\t5\n",
      "... [más resultados omitidos]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from MRE import Job\n",
    "root_path = './'\n",
    "inputDir = root_path + \"WordCount/input/\"\n",
    "outputDir = root_path + \"WordCount/ejercicio_2/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    words = value.split()\n",
    "    \n",
    "    for w in words:\n",
    "        context.write(w, 1)\n",
    "        \n",
    "def fred(key, values, context):\n",
    "    c=0\n",
    "    for v in values:\n",
    "        c=c+1\n",
    "    context.write(key, c)\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "job.setCombiner(fred)\n",
    "success = job.waitForCompletion()\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209636de-177f-4293-91f8-a2f53e096e3e",
   "metadata": {},
   "source": [
    "### Ejercicio 3)\n",
    "Implemente un job MapReduce para calcular el máximo, mínimo, promedio y desvío stándard de las ocurrencias de todas las palabras del dataset Libros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc799bd-e8ac-4f49-9b96-619a3a09c599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
