{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fc5fe6-6e5d-48b6-bad8-cecc1a2d459e",
   "metadata": {},
   "source": [
    "<div align='center'>\n",
    "\n",
    "# Practica 2\n",
    "\n",
    "<img src='https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExNTEwMTNpMGdpNHdkZncxbmhmN2t4cTZoams5bHZuNXlxcDg0ZnE5YSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/XIqCQx02E1U9W/giphy.gif'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318478e-c2e9-49ab-a66d-ad6d3a8f6486",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 1)\n",
    "Â¿En el dataset del ejercicio 1 de la prÃ¡ctica 1 indique para cada Job, si se verÃ­a beneficiado por una funciÃ³n combiner?\n",
    "\n",
    "En caso afirmativo,\n",
    "\n",
    "Â¿cuÃ¡l es la implementaciÃ³n de dicha funciÃ³n? Â¿QuÃ© datos recibe cada reduce, al utilizar la funciÃ³n combiner?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ca962-7047-420f-aa38-ada70ee73fb0",
   "metadata": {},
   "source": [
    "## Ejercicio 2)\n",
    "Implemente una funciÃ³n combiner para el problema del WordCount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862c096a-e224-4355-a583-e3a60a91c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m EL -> 1\n",
      "\u001b[94m[Map]\u001b[0m COFRE -> 1\n",
      "\u001b[94m[Map]\u001b[0m Repentino -> 1\n",
      "\u001b[94m[Map]\u001b[0m y -> 1\n",
      "\u001b[94m[Map]\u001b[0m formidable -> 1\n",
      "\u001b[94m[Map]\u001b[0m estrÃ©pito -> 1\n",
      "\u001b[94m[Map]\u001b[0m hÃ­zole -> 1\n",
      "\u001b[94m[Map]\u001b[0m volver -> 1\n",
      "\u001b[94m[Map]\u001b[0m el -> 1\n",
      "\u001b[94m[Map]\u001b[0m rostro -> 1\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: !ah! -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"A\" -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"B\" -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"Dr. -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"El -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"purgar\", -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: (aquÃƒÂ­ -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: (con -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: (naturalmente) -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: * -> [11, 1, 1, 1, 1]\n",
      "\u001b[96m... [mÃ¡s reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m!ah!\u001b[0m\t1\n",
      "\u001b[95m\"A\"\u001b[0m\t1\n",
      "\u001b[95m\"B\"\u001b[0m\t1\n",
      "\u001b[95m\"Dr.\u001b[0m\t1\n",
      "\u001b[95m\"El\u001b[0m\t1\n",
      "\u001b[95m\"purgar\",\u001b[0m\t1\n",
      "\u001b[95m(aquÃƒÂ­\u001b[0m\t1\n",
      "\u001b[95m(con\u001b[0m\t1\n",
      "\u001b[95m(naturalmente)\u001b[0m\t1\n",
      "\u001b[95m*\u001b[0m\t5\n",
      "\u001b[91m... [mÃ¡s resultados omitidos]\u001b[0m\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from MRE import Job\n",
    "\n",
    "inputDir = \"./practica_2_hadoop_mapReduce/WordCount/input/\"\n",
    "outputDir = \"./practica_2_hadoop_mapReduce/WordCount/ejercicio_2/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    words = value.split()\n",
    "    for w in words:\n",
    "        context.write(w, 1)\n",
    "        \n",
    "def fred(key, values, context):\n",
    "    c=0\n",
    "    for v in values:\n",
    "        c=c+1\n",
    "    context.write(key, c)\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "job.setCombiner(fred)\n",
    "success = job.waitForCompletion()\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209636de-177f-4293-91f8-a2f53e096e3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 3)\n",
    "Implemente un job MapReduce para calcular el mÃ¡ximo, mÃ­nimo, promedio y desvÃ­o stÃ¡ndard de las ocurrencias de todas las palabras del dataset Libros.\n",
    "\n",
    "#### Cuenta ocurrencias de cada palabra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac60f1c-c5c4-4a5b-972a-c191e92c6b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m el -> 1\n",
      "\u001b[94m[Map]\u001b[0m amo -> 1\n",
      "\u001b[94m[Map]\u001b[0m viejo -> 1\n",
      "\u001b[94m[Map]\u001b[0m nos -> 1\n",
      "\u001b[94m[Map]\u001b[0m apeamos -> 1\n",
      "\u001b[94m[Map]\u001b[0m de -> 1\n",
      "\u001b[94m[Map]\u001b[0m nuestras -> 1\n",
      "\u001b[94m[Map]\u001b[0m caballerÃ­as -> 1\n",
      "\u001b[94m[Map]\u001b[0m en -> 1\n",
      "\u001b[94m[Map]\u001b[0m un -> 1\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: * -> [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, '...']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --\"estimado -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --amigo -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --angustias -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --aquÃ­ -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --aun -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --buenas -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --buenos -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --comprendo -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --doctor -> [1]\n",
      "\u001b[96m... [mÃ¡s reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m*\u001b[0m\t15\n",
      "\u001b[95m--\"estimado\u001b[0m\t1\n",
      "\u001b[95m--amigo\u001b[0m\t2\n",
      "\u001b[95m--angustias\u001b[0m\t1\n",
      "\u001b[95m--aquÃ­\u001b[0m\t1\n",
      "\u001b[95m--aun\u001b[0m\t1\n",
      "\u001b[95m--buenas\u001b[0m\t2\n",
      "\u001b[95m--buenos\u001b[0m\t2\n",
      "\u001b[95m--comprendo\u001b[0m\t1\n",
      "\u001b[95m--doctor\u001b[0m\t1\n",
      "\u001b[91m... [mÃ¡s resultados omitidos]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from MRE import Job\n",
    "\n",
    "inputDir = \"./practica_2_hadoop_mapReduce/Libros/input\"\n",
    "wcDir = \"./practica_2_hadoop_mapReduce/Libros/ej3_wc/\"\n",
    "\n",
    "def fmap_wc(key, value, context):\n",
    "    # separar por espacios\n",
    "    for palabra in value.strip().split():\n",
    "        palabra = palabra.lower().strip(\".,;:Â¡!Â¿?\\\"()[]\")\n",
    "        if palabra:\n",
    "            context.write(palabra, 1)\n",
    "\n",
    "def fred_wc(key, values, context):\n",
    "    total = 0\n",
    "    for v in values:\n",
    "        total += v\n",
    "    context.write(key, total)\n",
    "\n",
    "job_wc = Job(inputDir, wcDir, fmap_wc, fred_wc)\n",
    "job_wc.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbd28d-0c99-4203-8e2f-e66d8c5cd8a3",
   "metadata": {},
   "source": [
    "#### Job de estadÃ­sticas (min, max, promedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e90ef1ab-d50d-4cee-bd99-d36ba947177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m min -> 15\n",
      "\u001b[94m[Map]\u001b[0m max -> 15\n",
      "\u001b[94m[Map]\u001b[0m avg -> 15\n",
      "\u001b[94m[Map]\u001b[0m min -> 1\n",
      "\u001b[94m[Map]\u001b[0m max -> 1\n",
      "\u001b[94m[Map]\u001b[0m avg -> 1\n",
      "\u001b[94m[Map]\u001b[0m min -> 1\n",
      "\u001b[94m[Map]\u001b[0m max -> 1\n",
      "\u001b[94m[Map]\u001b[0m avg -> 1\n",
      "\u001b[94m[Map]\u001b[0m min -> 1\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: avg -> [15, 1, 1, 1, 1, 1, 1, 1, 1, 3, '...']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: max -> [15, 1, 1, 1, 1, 1, 1, 1, 1, 3, '...']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: min -> [15, 1, 1, 1, 1, 1, 1, 1, 1, 3, '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mpromedio\u001b[0m\t3.4946911196911197\n",
      "\u001b[95mmax\u001b[0m\t839\n",
      "\u001b[95mmin\u001b[0m\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsDir = \"./practica_2_hadoop_mapReduce/Libros/ej3_stats/\"\n",
    "\n",
    "def fmap_stats(key, value, context):\n",
    "    ocurr = int(value.strip())\n",
    "    context.write(\"min\", ocurr)\n",
    "    context.write(\"max\", ocurr)\n",
    "    context.write(\"avg\", ocurr)\n",
    "\n",
    "def fred_stats(key, values, context):\n",
    "    if key == \"min\":\n",
    "        context.write(\"min\", min(values))\n",
    "    elif key == \"max\":\n",
    "        context.write(\"max\", max(values))\n",
    "    elif key == \"avg\":\n",
    "        total, n = 0, 0\n",
    "        for v in values:\n",
    "            total += v\n",
    "            n += 1\n",
    "        context.write(\"promedio\", total / n)\n",
    "\n",
    "job_stats = Job(wcDir, statsDir, fmap_stats, fred_stats)\n",
    "job_stats.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efaeab3-7370-4c65-b20f-cc095789f4d2",
   "metadata": {},
   "source": [
    "#### Job de desvÃ­o estÃ¡ndar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b44229-6789-4562-9843-22183b597ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m var -> 132.3721324313144\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 0.24471930390125368\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: var -> [132.3721324313144, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 0.24471930390125368, '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mdesvio\u001b[0m\t22.917022729315015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desvioDir = \"./practica_2_hadoop_mapReduce/Libros/ej3_desvio/\"\n",
    "\n",
    "import math\n",
    "\n",
    "def fmap_desvio(key, value, context):\n",
    "    ocurr = int(value.strip())\n",
    "    avg = context[\"avg\"]\n",
    "    context.write(\"var\", (ocurr - avg) ** 2)\n",
    "\n",
    "def fred_desvio(key, values, context):\n",
    "    total, n = 0, 0\n",
    "    for v in values:\n",
    "        total += v\n",
    "        n += 1\n",
    "    # varianza muestral\n",
    "    var = total / (n - 1)\n",
    "    context.write(\"desvio\", math.sqrt(var))\n",
    "\n",
    "# leer promedio del job_stats\n",
    "with open(statsDir + \"output.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "prom_line = [l for l in lines if l.startswith(\"promedio\")][0]\n",
    "promedio = float(prom_line.strip().split('\\t')[1])\n",
    "\n",
    "params = {\"avg\": promedio}\n",
    "job_desvio = Job(wcDir, desvioDir, fmap_desvio, fred_desvio)\n",
    "job_desvio.setParams(params)\n",
    "job_desvio.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcfe01d-a5b6-4ef3-920c-a150424e3608",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 4\n",
    "Utilice el dataset Libros para implementar una aplicaciÃ³n MapReduce que devuelva como salida todos los pÃ¡rrafos que tienen una longitud mayor al promedio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43b79a0-43be-4fbe-a111-97c57c349feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 13\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 321\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 337\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 599\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 33\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 112\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 177\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 64\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 457\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 269\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1 -> [13, 321, 337, 599, 33, 112, 177, 64, 457, 269, '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mpromedio\u001b[0m\t293.4931506849315\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m FRAY BALTASAR -> 13\n",
      "\u001b[94m[Map]\u001b[0m Cuando se hallÃƒÂ³, por fin, en la soledad del _Scriptorium_, tomÃƒÂ³ los pinceles con mano trÃƒÂ©mula y, sobre el estirado trozo de vitela, quiso reproducir una vez mÃƒÂ¡s las iluminaciones del misal del monasterio y del Libro de horas de la Reina de Francia; mas nada pudo lograr. Sus dibujos parecÃƒÂ­an los dibujos de un niÃƒÂ±o. -> 321\n",
      "\u001b[94m[Map]\u001b[0m Ninguno de los facultativos que consultÃ© encontraba remedio a mi mal, y no puse tÃ©rmino a mis dÃ­as con mi propia mano, gracias a mis principios religiosos. Por fin, siguiendo el consejo de no recuerdo quÃ© mÃ©dico famoso, determinÃ© que varios de los doctores mÃ¡s eminentes de la ciudad se reunieran en consulta, y despuÃ©s de dos horas del mÃ¡s penoso interrogatorio, pronunciaron mi sentencia. Mi mal era incurable y degenerarÃ­a en locura; el tumor que se habia formado en mi cerebro era inoperable y la muerte se aproximaba, aunque lentamente. -> 541\n",
      "\u001b[94m[Map]\u001b[0m InÃºtil me parece decir que la noticia de mi rÃ¡pida curaciÃ³n se extendiÃ³ por todo el paÃ­s, y el nombre del Dr. IdiÃ¡quez en seguida se hizo cÃ©lebre. De allÃ­ en adelante, efectuÃ³ las mÃ¡s sorprendentes curaciones, y al cabo de poco tiempo, reuniÃ³ una fortuna considerable. Lo que mÃ¡s intrigaba a sus pacientes era que jamÃ¡s recetaba, sino que Ã©l mismo proporcionaba las medicinas, marcÃ¡ndolas generalmente con letras, aunque a veces tambiÃ©n con nÃºmeros. -> 449\n",
      "\u001b[94m[Map]\u001b[0m A pesar de la estrecha amistad que unÃ­a a los HernÃ¡ndez de Sandoval con mi familia, desde largos aÃ±os, no habÃ­a yo tenido ocasiÃ³n de visitar ninguna de sus haciendas, aunque ellos sÃ­ habÃ­an pasado largas temporadas en la nuestra, situada en el centro del paÃ­s; de manera que, en cuanto se ofreciÃ³ la oportunidad de acompaÃ±ar al hijo de la casa, Antonio, pudiendo desprenderme de mis no mÃºltiples, pero sÃ­ imprescindibles quehaceres, la aprovechÃ© gustoso para ir en tan grata compaÃ±Ã­a a recorrer la finca principal de su casa, cÃ©lebre por su riqueza y encantos naturales. -> 570\n",
      "\u001b[94m[Map]\u001b[0m A pesar del cansancio que sentÃ­a, permanecÃ­ no corto espacio de tiempo en la soledad de aquella galerÃ­a, perdido en mis pensamientos, y con un leve zumbar de oÃ­dos, _oÃ­a el silencio_, que sÃ³lo interrumpÃ­a, de vez en cuando, el ladrar de un perro en el Â«realÂ» no lejano. -> 269\n",
      "\u001b[94m[Map]\u001b[0m No viene al caso referir nuestra vida en aquella finca durante la semana que en ella pasamos; sÃ³lo dirÃ© que durante seis noches, y aproximadamente a la misma hora, se repitiÃ³ el incidente de la primera, cosa que nos intrigÃ³ de tal modo, que nos propusimos descubrir al nocturno asmÃ¡tico. JuzgÃ³ Antonio lo mÃ¡s acertado ordenar a un tal Paulino, muy adicto suyo y hombre de toda confianza, que pasara la noche en mi estancia, en el umbral mismo de la puerta-ventana, para ayudar a aclarar el molesto, si bien un tanto ridÃ­culo misterio. -> 534\n",
      "\u001b[94m[Map]\u001b[0m Y le referÃ­ atropelladamente lo que acabÃ¡bamos de oÃ­r. -> 54\n",
      "\u001b[94m[Map]\u001b[0m --SÃ­gueme. -> 10\n",
      "\u001b[94m[Map]\u001b[0m Pasaron algunos meses. Un dÃ­a me dijo Antonio: -> 46\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: *       *       *       *       * -> [33, 33, 33]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --\"Estimado Padre RodrÃ­guez: Le ruego se sirva dar cristiana sepultura al portador de la presente. Su afmo. Hermano en Xto. _Alonso Hurtado, S.J._\" -> [147]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Amigo mÃ­o, ese es mi secreto; pero puesto que a usted le debo mi fortuna, se lo dirÃ©, si me promete, si me jura, no decirlo mientras yo viva. En cuanto muera, queda usted en libertad para proclamarlo a los cuatro vientos. -> [223]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Amigo, dijo el Padre Hurtado, en esta casa no tenemos jardÃ­n. -> [63]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Angustias, Â¿QuÃ© hacen los muertos de la capilla, en la noche? -> [63]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --AquÃ­ tienes, dijo Antonio, a la persona que prometÃ­ presentarte. Como ves, es una obra de arte. Se llama Herrera Goya. Para que no te rÃ­as de un miembro de la familia, te contarÃ© que Don JoaquÃ­n de Herrera Goya fuÃ© antepasado mÃ­o, aunque no en lÃ­nea recta, pues muriÃ³ soltero; su hermana, mi cuarta abuela, heredÃ³ de Ã©l esta hacienda y no sÃ© si a ella se deba tan hermosa estatua. Es costumbre pintarla cada aÃ±o; asÃ­ como hoy la ves color de rosa, ha estado pintada de celeste, amarillo, verde, de todo menos de negro, pues hay aquÃ­ la creencia,--cosas de los indios,--que si llegara a pintarse de ese color, ocurrirÃ­a alguna desgracia. La postura de sus manos indica, no que va a aplaudir, sino que la distancia que con ellos mide es el tamaÃ±o de los panes de azÃºcar que en su hacienda se fabricaban y que llenaron sus bolsillos de doblones. La tradiciÃ³n no cuenta cosas muy halagadoras para este seÃ±or; te las referirÃ© algÃºn dÃ­a. -> [933]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Aun vivo, Eminencia, repuso el Conde sonriendo, e hizo ademÃƒÂ¡n de besar la mano del Prelado, pero ÃƒÂ©ste la retirÃƒÂ³ disimuladamente indicando con ella una butaca cercana. TomÃƒÂ³ asiento el Conde, y despuÃƒÂ©s de unos instantes de embarazoso silencio, dijo: -> [254]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Buenas tardes, Padre, contestÃ³ Juan GonzÃ¡lez, con el rostro iluminado por la esperanza. -> [89]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Buenas tardes. -> [16]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Buenos dÃ­as, Padre. -> [21]\n",
      "\u001b[96m... [mÃ¡s reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mPÃ¡rrafo > promedio\u001b[0m\t*       *       *       *       *\n",
      "\u001b[95mPÃ¡rrafo > promedio\u001b[0m\t*       *       *       *       *\n",
      "\u001b[95mPÃ¡rrafo > promedio\u001b[0m\t*       *       *       *       *\n",
      "\u001b[95mPÃ¡rrafo > promedio\u001b[0m\t--\"Estimado Padre RodrÃ­guez: Le ruego se sirva dar cristiana sepultura al portador de la presente. Su afmo. Hermano en Xto. _Alonso Hurtado, S.J._\"\n",
      "\u001b[95mPÃ¡rrafo > promedio\u001b[0m\t--Amigo mÃ­o, ese es mi secreto; pero puesto que a usted le debo mi fortuna, se lo dirÃ©, si me promete, si me jura, no decirlo mientras yo viva. En cuanto muera, queda usted en libertad para proclamarlo a los cuatro vientos.\n",
      "\u001b[95mPÃ¡rrafo > promedio\u001b[0m\t--Amigo, dijo el Padre Hurtado, en esta casa no tenemos jardÃ­n.\n",
      "\u001b[95mPÃ¡rrafo > promedio\u001b[0m\t--Angustias, Â¿QuÃ© hacen los muertos de la capilla, en la noche?\n",
      "\u001b[95mPÃ¡rrafo > promedio\u001b[0m\t--AquÃ­ tienes, dijo Antonio, a la persona que prometÃ­ presentarte. Como ves, es una obra de arte. Se llama Herrera Goya. Para que no te rÃ­as de un miembro de la familia, te contarÃ© que Don JoaquÃ­n de Herrera Goya fuÃ© antepasado mÃ­o, aunque no en lÃ­nea recta, pues muriÃ³ soltero; su hermana, mi cuarta abuela, heredÃ³ de Ã©l esta hacienda y no sÃ© si a ella se deba tan hermosa estatua. Es costumbre pintarla cada aÃ±o; asÃ­ como hoy la ves color de rosa, ha estado pintada de celeste, amarillo, verde, de todo menos de negro, pues hay aquÃ­ la creencia,--cosas de los indios,--que si llegara a pintarse de ese color, ocurrirÃ­a alguna desgracia. La postura de sus manos indica, no que va a aplaudir, sino que la distancia que con ellos mide es el tamaÃ±o de los panes de azÃºcar que en su hacienda se fabricaban y que llenaron sus bolsillos de doblones. La tradiciÃ³n no cuenta cosas muy halagadoras para este seÃ±or; te las referirÃ© algÃºn dÃ­a.\n",
      "\u001b[95mPÃ¡rrafo > promedio\u001b[0m\t--Aun vivo, Eminencia, repuso el Conde sonriendo, e hizo ademÃƒÂ¡n de besar la mano del Prelado, pero ÃƒÂ©ste la retirÃƒÂ³ disimuladamente indicando con ella una butaca cercana. TomÃƒÂ³ asiento el Conde, y despuÃƒÂ©s de unos instantes de embarazoso silencio, dijo:\n",
      "\u001b[95mPÃ¡rrafo > promedio\u001b[0m\t--Buenas tardes, Padre, contestÃ³ Juan GonzÃ¡lez, con el rostro iluminado por la esperanza.\n",
      "\u001b[91m... [mÃ¡s resultados omitidos]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, math\n",
    "sys.path.append(\"..\")\n",
    "from MRE import Job\n",
    "\n",
    "librosDir = \"./practica_2_hadoop_mapReduce/Libros/input\"\n",
    "out1Dir = \"./practica_2_hadoop_mapReduce/Libros/ej4_out1/\"\n",
    "\n",
    "# ===== Job 1: promedio de longitud de pÃ¡rrafos =====\n",
    "def fmap_len(key, value, context):\n",
    "    length = len(value.strip())\n",
    "    context.write(1, length)\n",
    "\n",
    "def fred_len(key, values, context):\n",
    "    total, n = 0, 0\n",
    "    for v in values:\n",
    "        total += v\n",
    "        n += 1\n",
    "    avg = total / n if n > 0 else 0\n",
    "    context.write(\"promedio\", avg)\n",
    "\n",
    "job1 = Job(librosDir, out1Dir, fmap_len, fred_len)\n",
    "job1.waitForCompletion()\n",
    "\n",
    "out2Dir = \"./Libros/ej4_out2/\"\n",
    "\n",
    "# ===== Job 2: filtrar pÃ¡rrafos mayores al promedio =====\n",
    "def fmap_filter(key, value, context):\n",
    "    length = len(value.strip())\n",
    "    context.write(value.strip(), length)\n",
    "\n",
    "def fred_filter(parrafo, values, context):\n",
    "    avg = context[\"avg\"]\n",
    "    for v in values:\n",
    "        if v > avg:\n",
    "            context.write(\"PÃ¡rrafo > promedio\", parrafo)\n",
    "\n",
    "params = {\"avg\": promedio}\n",
    "job2 = Job(librosDir, out2Dir, fmap_filter, fred_filter)\n",
    "job2.setParams(params)\n",
    "job2.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec15c4b-9c10-4632-a7a2-fd92672b0ec2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 5\n",
    "\n",
    "El dataset website tiene informaciÃ³n sobre el tiempo de permanencia de sus usuarios\n",
    "en cada una de las pÃ¡ginas del sitio. El formato de los datos del dataset es:\n",
    "<id_user, id_page, time>\n",
    "Implemente una aplicaciÃ³n MapReduce, utilizando combiners en los casos que\n",
    "considere necesario, que calcule\n",
    "\n",
    "> Indique como queda el DAG del proceso completo (las tres consultas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723344e-ca9b-45bb-9ace-f13c21f96808",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### a. La pÃ¡gina mÃ¡s visitada (la pÃ¡gina en la que mÃ¡s tiempo permaneciÃ³) para cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cecff47-6285-4ecd-948b-4ff5c26a878b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m ('9697', '1539') -> 79\n",
      "\u001b[94m[Map]\u001b[0m ('11421', '1470') -> 5\n",
      "\u001b[94m[Map]\u001b[0m ('11071', '2454') -> 94\n",
      "\u001b[94m[Map]\u001b[0m ('11645', '2407') -> 35\n",
      "\u001b[94m[Map]\u001b[0m ('11294', '1352') -> 16\n",
      "\u001b[94m[Map]\u001b[0m ('13592', '1645') -> 2\n",
      "\u001b[94m[Map]\u001b[0m ('13346', '2318') -> 29\n",
      "\u001b[94m[Map]\u001b[0m ('9068', '2015') -> 78\n",
      "\u001b[94m[Map]\u001b[0m ('14963', '1227') -> 74\n",
      "\u001b[94m[Map]\u001b[0m ('12846', '3144') -> 34\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10000', '2332') -> [81]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10000', '2852') -> [52]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10001', '2903') -> [82]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10002', '1353') -> [27]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10002', '2699') -> [24]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10004', '3676') -> [30]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10005', '3079') -> [21]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10007', '1084') -> [6]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10007', '3095') -> [65]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10008', '1986') -> [6]\n",
      "\u001b[96m... [mÃ¡s reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m('10000', '2332')\u001b[0m\t81\n",
      "\u001b[95m('10000', '2852')\u001b[0m\t52\n",
      "\u001b[95m('10001', '2903')\u001b[0m\t82\n",
      "\u001b[95m('10002', '1353')\u001b[0m\t27\n",
      "\u001b[95m('10002', '2699')\u001b[0m\t24\n",
      "\u001b[95m('10004', '3676')\u001b[0m\t30\n",
      "\u001b[95m('10005', '3079')\u001b[0m\t21\n",
      "\u001b[95m('10007', '1084')\u001b[0m\t6\n",
      "\u001b[95m('10007', '3095')\u001b[0m\t65\n",
      "\u001b[95m('10008', '1986')\u001b[0m\t6\n",
      "\u001b[91m... [mÃ¡s resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 10000 -> ('2332', 81)\n",
      "\u001b[94m[Map]\u001b[0m 10008 -> ('2693', 34)\n",
      "\u001b[94m[Map]\u001b[0m 10024 -> ('2491', 95)\n",
      "\u001b[94m[Map]\u001b[0m 10032 -> ('3077', 13)\n",
      "\u001b[94m[Map]\u001b[0m 10045 -> ('2016', 19)\n",
      "\u001b[94m[Map]\u001b[0m 10060 -> ('2797', 3)\n",
      "\u001b[94m[Map]\u001b[0m 10070 -> ('1194', 3)\n",
      "\u001b[94m[Map]\u001b[0m 10080 -> ('1724', 92)\n",
      "\u001b[94m[Map]\u001b[0m 10092 -> ('3902', 46)\n",
      "\u001b[94m[Map]\u001b[0m 10105 -> ('1291', 32)\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10000 -> [('2332', 81), ('2852', 52)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10001 -> [('2903', 82)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10002 -> [('1353', 27), ('2699', 24)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10004 -> [('3676', 30)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10005 -> [('3079', 21)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10007 -> [('1084', 6), ('3095', 65)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10008 -> [('2693', 34), ('1986', 6)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10009 -> [('1586', 48), ('3638', 9), ('3926', 63)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10011 -> [('2720', 71)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10012 -> [('3152', 67)]\n",
      "\u001b[96m... [mÃ¡s reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m10000\u001b[0m\t2332\n",
      "\u001b[95m10001\u001b[0m\t2903\n",
      "\u001b[95m10002\u001b[0m\t1353\n",
      "\u001b[95m10004\u001b[0m\t3676\n",
      "\u001b[95m10005\u001b[0m\t3079\n",
      "\u001b[95m10007\u001b[0m\t3095\n",
      "\u001b[95m10008\u001b[0m\t2693\n",
      "\u001b[95m10009\u001b[0m\t3926\n",
      "\u001b[95m10011\u001b[0m\t2720\n",
      "\u001b[95m10012\u001b[0m\t3152\n",
      "\u001b[91m... [mÃ¡s resultados omitidos]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from MRE import Job\n",
    "\n",
    "# directorios de trabajo\n",
    "inputDir = \"./practica_2_hadoop_mapReduce/website/input/\"\n",
    "out1 = \"./practica_2_hadoop_mapReduce/website/out_A1/\"\n",
    "out2 = \"./practica_2_hadoop_mapReduce/website/out_A2/\"\n",
    "\n",
    "# agrupa por (user, page)\n",
    "def fmap_1(user_id, value, context):\n",
    "    parts = value.strip().split('\\t')\n",
    "    page_id, time = parts\n",
    "    context.write((user_id, page_id), int(time))\n",
    "\n",
    "# reduce: suma tiempos por (user, page)\n",
    "def fred_1(key, values, context):\n",
    "    total_time = 0\n",
    "    for t in values:\n",
    "        total_time += t\n",
    "    context.write(key, total_time)\n",
    "\n",
    "# agrupa por user\n",
    "def fmap_2(user_id, value, context):\n",
    "    parts = value.strip().split('\\t')\n",
    "    page_id, total_time = parts\n",
    "    context.write(user_id, (page_id, int(total_time)))\n",
    "\n",
    "# reduce: selecciona la pÃ¡gina con mÃ¡s tiempo\n",
    "def fred_2(user_id, values, context):\n",
    "    max_time = -1\n",
    "    best_page = None\n",
    "    for page_id, t in values:\n",
    "        if t > max_time:\n",
    "            max_time = t\n",
    "            best_page = page_id\n",
    "    context.write(user_id, best_page)\n",
    "\n",
    "job1 = Job(inputDir, out1, fmap_1, fred_1)\n",
    "job1.setCombiner(fred_1)\n",
    "job1.waitForCompletion()\n",
    "\n",
    "job2 = Job(out1, out2, fmap_2, fred_2)\n",
    "job2.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c7a132-a434-4ebe-a719-6483a1b82680",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### b. El usuario que mÃ¡s pÃ¡ginas distintas visitÃ³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92136928-4243-49eb-a423-4073181ff086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 10000 -> 2332\n",
      "\u001b[94m[Map]\u001b[0m 10008 -> 2693\n",
      "\u001b[94m[Map]\u001b[0m 10024 -> 2491\n",
      "\u001b[94m[Map]\u001b[0m 10032 -> 3077\n",
      "\u001b[94m[Map]\u001b[0m 10045 -> 2016\n",
      "\u001b[94m[Map]\u001b[0m 10060 -> 2797\n",
      "\u001b[94m[Map]\u001b[0m 10070 -> 1194\n",
      "\u001b[94m[Map]\u001b[0m 10080 -> 1724\n",
      "\u001b[94m[Map]\u001b[0m 10092 -> 3902\n",
      "\u001b[94m[Map]\u001b[0m 10105 -> 1291\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10000 -> ['2332', '2852']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10001 -> ['2903']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10002 -> ['1353', '2699']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10004 -> ['3676']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10005 -> ['3079']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10007 -> ['1084', '3095']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10008 -> ['2693', '1986']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10009 -> ['1586', '3638', '3926']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10011 -> ['2720']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10012 -> ['3152']\n",
      "\u001b[96m... [mÃ¡s reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m10000\u001b[0m\t2\n",
      "\u001b[95m10001\u001b[0m\t1\n",
      "\u001b[95m10002\u001b[0m\t2\n",
      "\u001b[95m10004\u001b[0m\t1\n",
      "\u001b[95m10005\u001b[0m\t1\n",
      "\u001b[95m10007\u001b[0m\t2\n",
      "\u001b[95m10008\u001b[0m\t2\n",
      "\u001b[95m10009\u001b[0m\t3\n",
      "\u001b[95m10011\u001b[0m\t1\n",
      "\u001b[95m10012\u001b[0m\t1\n",
      "\u001b[91m... [mÃ¡s resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10000', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10013', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10036', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10054', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10070', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10090', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10110', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10125', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10143', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10167', 1)\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1 -> [('10000', 2), ('10013', 1), ('10036', 2), ('10054', 3), ('10070', 2), ('10090', 1), ('10110', 1), ('10125', 1), ('10143', 1), ('10167', 1), '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mUsuario con mÃ¡s pÃ¡ginas distintas\u001b[0m\t('9458', 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directorios de salida para inciso B\n",
    "out3 = \"./practica_2_hadoop_mapReduce/website/out_B1/\"\n",
    "out4 = \"./practica_2_hadoop_mapReduce/website/out_B2/\"\n",
    "\n",
    "# cuenta pÃ¡ginas distintas por usuario\n",
    "def fmap_3(user_id, value, context):\n",
    "    parts = value.strip().split('\\t')\n",
    "    page_id, _ = parts\n",
    "    context.write(user_id, page_id)\n",
    "\n",
    "def fred_3(user_id, values, context):\n",
    "    distinct_pages = set(values)\n",
    "    context.write(user_id, len(distinct_pages))\n",
    "\n",
    "# agrupa todos los (user, count) bajo una misma clave\n",
    "def fmap_4(user_id, value, context):\n",
    "    context.write(1, (user_id, int(value.strip())))\n",
    "\n",
    "def fred_max(_, values, context):\n",
    "    best_user, max_count = None, -1\n",
    "    for user, c in values:\n",
    "        if c > max_count:\n",
    "            max_count = c\n",
    "            best_user = user\n",
    "    context.write(\"Usuario con mÃ¡s pÃ¡ginas distintas\", (best_user, max_count))\n",
    "\n",
    "job3 = Job(out1, out3, fmap_3, fred_3)\n",
    "job3.waitForCompletion()\n",
    "\n",
    "job4 = Job(out3, out4, fmap_4, fred_max)\n",
    "job4.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c7dc4-a7dd-414f-b647-4eb6000d7b54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### c. La pÃ¡gina mÃ¡s visitada (en cuanto a cantidad de visitas, sin importar el tiempo de permanencia) por todos los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f8ffa30-b569-4cc8-a746-683c5056a84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1071 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3188 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3401 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 2326 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 2394 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3614 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1532 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 2813 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3916 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3869 -> 1\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1000 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1001 -> [1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1002 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1003 -> [1, 1, 1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1005 -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1006 -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1007 -> [1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1008 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1010 -> [1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1011 -> [1, 1]\n",
      "\u001b[96m... [mÃ¡s reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m1000\u001b[0m\t1\n",
      "\u001b[95m1001\u001b[0m\t3\n",
      "\u001b[95m1002\u001b[0m\t1\n",
      "\u001b[95m1003\u001b[0m\t5\n",
      "\u001b[95m1005\u001b[0m\t2\n",
      "\u001b[95m1006\u001b[0m\t2\n",
      "\u001b[95m1007\u001b[0m\t3\n",
      "\u001b[95m1008\u001b[0m\t1\n",
      "\u001b[95m1010\u001b[0m\t3\n",
      "\u001b[95m1011\u001b[0m\t2\n",
      "\u001b[91m... [mÃ¡s resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1000 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1012 -> 3\n",
      "\u001b[94m[Map]\u001b[0m 1025 -> 2\n",
      "\u001b[94m[Map]\u001b[0m 1036 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1047 -> 3\n",
      "\u001b[94m[Map]\u001b[0m 1058 -> 2\n",
      "\u001b[94m[Map]\u001b[0m 1073 -> 2\n",
      "\u001b[94m[Map]\u001b[0m 1085 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1096 -> 3\n",
      "\u001b[94m[Map]\u001b[0m 1107 -> 2\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1000 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1001 -> [3]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1002 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1003 -> [5]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1005 -> [2]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1006 -> [2]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1007 -> [3]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1008 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1010 -> [3]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1011 -> [2]\n",
      "\u001b[96m... [mÃ¡s reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m1000\u001b[0m\t1\n",
      "\u001b[95m1001\u001b[0m\t3\n",
      "\u001b[95m1002\u001b[0m\t1\n",
      "\u001b[95m1003\u001b[0m\t5\n",
      "\u001b[95m1005\u001b[0m\t2\n",
      "\u001b[95m1006\u001b[0m\t2\n",
      "\u001b[95m1007\u001b[0m\t3\n",
      "\u001b[95m1008\u001b[0m\t1\n",
      "\u001b[95m1010\u001b[0m\t3\n",
      "\u001b[95m1011\u001b[0m\t2\n",
      "\u001b[91m... [mÃ¡s resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1000', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1012', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1025', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1036', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1047', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1058', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1073', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1085', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1096', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1107', 2)\n",
      "\u001b[94m... [mÃ¡s resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÃ“N...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1 -> [('1000', 1), ('1012', 3), ('1025', 2), ('1036', 1), ('1047', 3), ('1058', 2), ('1073', 2), ('1085', 1), ('1096', 3), ('1107', 2), '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mPÃ¡gina mÃ¡s visitada\u001b[0m\t('1694', 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directorios de salida para inciso C\n",
    "out5 = \"./practica_2_hadoop_mapReduce/website/out_C1/\"\n",
    "out6 = \"./practica_2_hadoop_mapReduce/website/out_C2/\"\n",
    "out7 = \"./practica_2_hadoop_mapReduce/website/out_C3/\"\n",
    "\n",
    "# ---------------- JOB 5 ----------------\n",
    "# Emite (page_id, 1) por cada visita\n",
    "def fmap_5(user_id, value, context):\n",
    "    parts = value.strip().split('\\t') \n",
    "    page_id, time = parts   # el tiempo no importa acÃ¡\n",
    "    context.write(page_id, 1)\n",
    "\n",
    "def fred_count(page_id, values, context):\n",
    "    total_visits = sum(values)\n",
    "    context.write(page_id, total_visits)\n",
    "\n",
    "# ---------------- JOB 6 ----------------\n",
    "# Junta todas las visitas de cada pÃ¡gina (ya estÃ¡n como enteros)\n",
    "def fmap_6(page_id, value, context):\n",
    "    context.write(page_id, int(value.strip()))\n",
    "\n",
    "def fred_sum(page_id, values, context):\n",
    "    total = sum(values)\n",
    "    context.write(page_id, total)\n",
    "\n",
    "# ---------------- JOB 7 ----------------\n",
    "# Busca la pÃ¡gina con mÃ¡s visitas\n",
    "def fmap_7(page_id, value, context):\n",
    "    context.write(1, (page_id, int(value.strip())))\n",
    "\n",
    "def fred_max(_, values, context):\n",
    "    max_count = -1\n",
    "    best_page = None\n",
    "    for page, count in values:\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            best_page = page\n",
    "    context.write(\"PÃ¡gina mÃ¡s visitada\", (best_page, max_count))\n",
    "\n",
    "job5 = Job(inputDir, out5, fmap_5, fred_count)\n",
    "job5.waitForCompletion()\n",
    "\n",
    "job6 = Job(out5, out6, fmap_6, fred_sum)\n",
    "job6.waitForCompletion()\n",
    "\n",
    "job7 = Job(out6, out7, fmap_7, fred_max)\n",
    "job7.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0d5ca-3366-409a-a318-f5c209773fca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6) CÃ³mo plantearÃ­a una soluciÃ³n MapReduce a los siguientes algoritmos secuenciales:\n",
    "\n",
    "i. entrada\n",
    "\n",
    "```\n",
    "textos: array [1..N] of string (dataset libros)\n",
    "```\n",
    "ii. algoritmo\n",
    "\n",
    "```python\n",
    "a={}; b={}; N = len(textos)\n",
    "for l in textos:\n",
    "    words = l.split()\n",
    "    for w in words:\n",
    "        a[w] = a[w]+1\n",
    "\n",
    "for w in a.keys():\n",
    "    for l in lines:\n",
    "        words = l.split()\n",
    "        if w in words:\n",
    "            b[w]=b[w]+1\n",
    "for k in a.keys():\n",
    "    print(k + \" = \" + str(a[w] * (N / b[w])))\n",
    "```\n",
    "\n",
    "El algoritmo secuencial trabaja como una variante de **TF-IDF** (frecuencia de palabra por documento).\n",
    "Hace tres cosas:\n",
    "\n",
    "1. Cuenta cuÃ¡ntas veces aparece cada palabra en todo el dataset (`a[w]`).\n",
    "2. Cuenta en cuÃ¡ntos documentos (lÃ­neas o pÃ¡rrafos) aparece cada palabra (`b[w]`).\n",
    "3. Devuelve para cada palabra: `a[w] * (N / b[w])`, donde `N` es la cantidad total de documentos.\n",
    "\n",
    "**CÃ³mo se plantea en MapReduce**\n",
    "\n",
    "Este problema no se resuelve con un solo job, sino con **tres jobs encadenados**:\n",
    "\n",
    "* **Job 1 (contar ocurrencias totales de palabras):**\n",
    "\n",
    "  * *Map:* cada mapper toma un documento y por cada palabra emite `(palabra, 1)`.\n",
    "  * *Reduce:* los reducers suman esos 1 y obtienen cuÃ¡ntas veces aparece cada palabra en todo el dataset.\n",
    "  * **Salida:** `(palabra, total_ocurrencias)` â†’ esto es `a[w]`.\n",
    "\n",
    "* **Job 2 (contar en cuÃ¡ntos documentos aparece cada palabra):**\n",
    "\n",
    "  * *Map:* cada mapper toma un documento y por cada palabra distinta en ese documento emite `(palabra, doc_id)`.\n",
    "  * *Reduce:* para cada palabra, cuenta la cantidad de `doc_id` distintos â†’ en cuÃ¡ntos documentos aparece.\n",
    "  * **Salida:** `(palabra, num_docs)` â†’ esto es `b[w]`.\n",
    "\n",
    "* **Job 3 (cÃ¡lculo final):**\n",
    "\n",
    "  * *Map:* se unen las salidas de Job1 y Job2 por clave (la palabra).\n",
    "  * *Reduce:* con `a[w]` y `b[w]` calcula `a[w] * (N / b[w])`.\n",
    "  * **Salida final:** `(palabra, score)`.\n",
    "\n",
    "ðŸ”— El **DAG** se ve asÃ­:\n",
    "\n",
    "```\n",
    "Dataset Libros\n",
    " â”œâ”€ Job1 â†’ a[w] = total ocurrencias\n",
    " â”œâ”€ Job2 â†’ b[w] = nÂº de documentos con w\n",
    " â””â”€ Job3 (join y cÃ¡lculo) â†’ resultado final\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "b.\n",
    "i. entrada\n",
    "```\n",
    "datos: array [1..N] of /<int1, int2, ..., intM> (todos los valores estÃ¡n dentro de un rango de valores conocido, para poder usarlos como Ã­ndices del tensor)\n",
    "```\n",
    "ii. algoritmo\n",
    "\n",
    "```python\n",
    "for t in datos:\n",
    "    v = t.split(\"\\t\")\n",
    "    c = v[-1]\n",
    "        for a in range(len(v)-1):\n",
    "        x= v[a]\n",
    "        m[a][x][c] = m[a][x][c] + 1\n",
    "\n",
    "max=[[0,0,0], [0,0,0]]\n",
    "for x in range(len(m)):\n",
    "    for y in range(len(m[0])):\n",
    "        for z in range(2):\n",
    "            if(m[x][y][z] > max[z][0]):\n",
    "                max[z][0] = m[x][y][z]\n",
    "                max[z][1]=x\n",
    "                max[z][2]=y\n",
    "\n",
    "for z in range(2):\n",
    "    print(z +\";\" + max[z][1] +\";\" + max[z][2])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "El algoritmo secuencial toma un dataset de tuplas `<x1, x2, â€¦, xM, c>` (atributos + clase).\n",
    "Hace dos cosas:\n",
    "\n",
    "1. Construye una especie de â€œtensor de frecuenciasâ€ `m[a][x][c]`, que cuenta cuÃ¡ntas veces el atributo `a` tomÃ³ el valor `x` en ejemplos de clase `c`.\n",
    "2. Busca, para cada clase `c`, cuÃ¡l es el valor de atributo que mÃ¡s se repite.\n",
    "\n",
    "**CÃ³mo se plantea en MapReduce**\n",
    "\n",
    "Este problema se resuelve en **dos jobs**:\n",
    "\n",
    "* **Job 1 (conteo de triples atributoâ€“valorâ€“clase):**\n",
    "\n",
    "  * *Map:* para cada tupla `<x1, â€¦, xM, c>`, emite `(a, x, c) â†’ 1` para cada atributo `a` y su valor `x`.\n",
    "  * *Reduce:* para cada triple `(a, x, c)` suma todas las ocurrencias.\n",
    "  * **Salida:** `(a, x, c, count)` â†’ cuÃ¡ntas veces apareciÃ³ el valor `x` del atributo `a` en la clase `c`.\n",
    "\n",
    "* **Job 2 (buscar mÃ¡ximos por clase):**\n",
    "\n",
    "  * *Map:* reemite los resultados del Job 1 pero agrupando por clase `c`.\n",
    "  * *Reduce:* para cada clase `c`, recorre todos los `(a, x, count)` y selecciona el de mayor frecuencia.\n",
    "  * **Salida final:** `(c, mejor atributo=a, valor=x, count)`.\n",
    "\n",
    "ðŸ”— El **DAG** se ve asÃ­:\n",
    "\n",
    "```\n",
    "Dataset Datos\n",
    " â”œâ”€ Job1 â†’ conteo de (atributo, valor, clase)\n",
    " â””â”€ Job2 â†’ selecciÃ³n del mÃ¡ximo por clase\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f6aa4-cfd5-4146-b041-28fdc562dfac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
