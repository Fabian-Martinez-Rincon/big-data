{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fc5fe6-6e5d-48b6-bad8-cecc1a2d459e",
   "metadata": {},
   "source": [
    "<div align='center'>\n",
    "\n",
    "# Practica 2\n",
    "\n",
    "<img src='https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExNTEwMTNpMGdpNHdkZncxbmhmN2t4cTZoams5bHZuNXlxcDg0ZnE5YSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/XIqCQx02E1U9W/giphy.gif'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318478e-c2e9-49ab-a66d-ad6d3a8f6486",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 1)\n",
    "¿En el dataset del ejercicio 1 de la práctica 1 indique para cada Job, si se vería beneficiado por una función combiner?\n",
    "\n",
    "En caso afirmativo,\n",
    "\n",
    "¿cuál es la implementación de dicha función? ¿Qué datos recibe cada reduce, al utilizar la función combiner?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ca962-7047-420f-aa38-ada70ee73fb0",
   "metadata": {},
   "source": [
    "## Ejercicio 2)\n",
    "Implemente una función combiner para el problema del WordCount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862c096a-e224-4355-a583-e3a60a91c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m EL -> 1\n",
      "\u001b[94m[Map]\u001b[0m COFRE -> 1\n",
      "\u001b[94m[Map]\u001b[0m Repentino -> 1\n",
      "\u001b[94m[Map]\u001b[0m y -> 1\n",
      "\u001b[94m[Map]\u001b[0m formidable -> 1\n",
      "\u001b[94m[Map]\u001b[0m estrépito -> 1\n",
      "\u001b[94m[Map]\u001b[0m hízole -> 1\n",
      "\u001b[94m[Map]\u001b[0m volver -> 1\n",
      "\u001b[94m[Map]\u001b[0m el -> 1\n",
      "\u001b[94m[Map]\u001b[0m rostro -> 1\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: !ah! -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"A\" -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"B\" -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"Dr. -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"El -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"purgar\", -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: (aquÃ­ -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: (con -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: (naturalmente) -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: * -> [11, 1, 1, 1, 1]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m!ah!\u001b[0m\t1\n",
      "\u001b[95m\"A\"\u001b[0m\t1\n",
      "\u001b[95m\"B\"\u001b[0m\t1\n",
      "\u001b[95m\"Dr.\u001b[0m\t1\n",
      "\u001b[95m\"El\u001b[0m\t1\n",
      "\u001b[95m\"purgar\",\u001b[0m\t1\n",
      "\u001b[95m(aquÃ­\u001b[0m\t1\n",
      "\u001b[95m(con\u001b[0m\t1\n",
      "\u001b[95m(naturalmente)\u001b[0m\t1\n",
      "\u001b[95m*\u001b[0m\t5\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from MRE import Job\n",
    "\n",
    "inputDir = \"./practica_2_hadoop_mapReduce/WordCount/input/\"\n",
    "outputDir = \"./practica_2_hadoop_mapReduce/WordCount/ejercicio_2/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    words = value.split()\n",
    "    for w in words:\n",
    "        context.write(w, 1)\n",
    "        \n",
    "def fred(key, values, context):\n",
    "    c=0\n",
    "    for v in values:\n",
    "        c=c+1\n",
    "    context.write(key, c)\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "job.setCombiner(fred)\n",
    "success = job.waitForCompletion()\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209636de-177f-4293-91f8-a2f53e096e3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 3)\n",
    "Implemente un job MapReduce para calcular el máximo, mínimo, promedio y desvío stándard de las ocurrencias de todas las palabras del dataset Libros.\n",
    "\n",
    "#### Cuenta ocurrencias de cada palabra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac60f1c-c5c4-4a5b-972a-c191e92c6b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m el -> 1\n",
      "\u001b[94m[Map]\u001b[0m amo -> 1\n",
      "\u001b[94m[Map]\u001b[0m viejo -> 1\n",
      "\u001b[94m[Map]\u001b[0m nos -> 1\n",
      "\u001b[94m[Map]\u001b[0m apeamos -> 1\n",
      "\u001b[94m[Map]\u001b[0m de -> 1\n",
      "\u001b[94m[Map]\u001b[0m nuestras -> 1\n",
      "\u001b[94m[Map]\u001b[0m caballerías -> 1\n",
      "\u001b[94m[Map]\u001b[0m en -> 1\n",
      "\u001b[94m[Map]\u001b[0m un -> 1\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: * -> [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, '...']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --\"estimado -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --amigo -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --angustias -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --aquí -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --aun -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --buenas -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --buenos -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --comprendo -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --doctor -> [1]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m*\u001b[0m\t15\n",
      "\u001b[95m--\"estimado\u001b[0m\t1\n",
      "\u001b[95m--amigo\u001b[0m\t2\n",
      "\u001b[95m--angustias\u001b[0m\t1\n",
      "\u001b[95m--aquí\u001b[0m\t1\n",
      "\u001b[95m--aun\u001b[0m\t1\n",
      "\u001b[95m--buenas\u001b[0m\t2\n",
      "\u001b[95m--buenos\u001b[0m\t2\n",
      "\u001b[95m--comprendo\u001b[0m\t1\n",
      "\u001b[95m--doctor\u001b[0m\t1\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from MRE import Job\n",
    "\n",
    "inputDir = \"./practica_2_hadoop_mapReduce/Libros/input\"\n",
    "wcDir = \"./practica_2_hadoop_mapReduce/Libros/ej3_wc/\"\n",
    "\n",
    "def fmap_wc(key, value, context):\n",
    "    # separar por espacios\n",
    "    for palabra in value.strip().split():\n",
    "        palabra = palabra.lower().strip(\".,;:¡!¿?\\\"()[]\")\n",
    "        if palabra:\n",
    "            context.write(palabra, 1)\n",
    "\n",
    "def fred_wc(key, values, context):\n",
    "    total = 0\n",
    "    for v in values:\n",
    "        total += v\n",
    "    context.write(key, total)\n",
    "\n",
    "job_wc = Job(inputDir, wcDir, fmap_wc, fred_wc)\n",
    "job_wc.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbd28d-0c99-4203-8e2f-e66d8c5cd8a3",
   "metadata": {},
   "source": [
    "#### Job de estadísticas (min, max, promedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e90ef1ab-d50d-4cee-bd99-d36ba947177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m min -> 15\n",
      "\u001b[94m[Map]\u001b[0m max -> 15\n",
      "\u001b[94m[Map]\u001b[0m avg -> 15\n",
      "\u001b[94m[Map]\u001b[0m min -> 1\n",
      "\u001b[94m[Map]\u001b[0m max -> 1\n",
      "\u001b[94m[Map]\u001b[0m avg -> 1\n",
      "\u001b[94m[Map]\u001b[0m min -> 1\n",
      "\u001b[94m[Map]\u001b[0m max -> 1\n",
      "\u001b[94m[Map]\u001b[0m avg -> 1\n",
      "\u001b[94m[Map]\u001b[0m min -> 1\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: avg -> [15, 1, 1, 1, 1, 1, 1, 1, 1, 3, '...']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: max -> [15, 1, 1, 1, 1, 1, 1, 1, 1, 3, '...']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: min -> [15, 1, 1, 1, 1, 1, 1, 1, 1, 3, '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mpromedio\u001b[0m\t3.4946911196911197\n",
      "\u001b[95mmax\u001b[0m\t839\n",
      "\u001b[95mmin\u001b[0m\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsDir = \"./practica_2_hadoop_mapReduce/Libros/ej3_stats/\"\n",
    "\n",
    "def fmap_stats(key, value, context):\n",
    "    ocurr = int(value.strip())\n",
    "    context.write(\"min\", ocurr)\n",
    "    context.write(\"max\", ocurr)\n",
    "    context.write(\"avg\", ocurr)\n",
    "\n",
    "def fred_stats(key, values, context):\n",
    "    if key == \"min\":\n",
    "        context.write(\"min\", min(values))\n",
    "    elif key == \"max\":\n",
    "        context.write(\"max\", max(values))\n",
    "    elif key == \"avg\":\n",
    "        total, n = 0, 0\n",
    "        for v in values:\n",
    "            total += v\n",
    "            n += 1\n",
    "        context.write(\"promedio\", total / n)\n",
    "\n",
    "job_stats = Job(wcDir, statsDir, fmap_stats, fred_stats)\n",
    "job_stats.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efaeab3-7370-4c65-b20f-cc095789f4d2",
   "metadata": {},
   "source": [
    "#### Job de desvío estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b44229-6789-4562-9843-22183b597ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m var -> 132.3721324313144\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 0.24471930390125368\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: var -> [132.3721324313144, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 0.24471930390125368, '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mdesvio\u001b[0m\t22.917022729315015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desvioDir = \"./practica_2_hadoop_mapReduce/Libros/ej3_desvio/\"\n",
    "\n",
    "import math\n",
    "\n",
    "def fmap_desvio(key, value, context):\n",
    "    ocurr = int(value.strip())\n",
    "    avg = context[\"avg\"]\n",
    "    context.write(\"var\", (ocurr - avg) ** 2)\n",
    "\n",
    "def fred_desvio(key, values, context):\n",
    "    total, n = 0, 0\n",
    "    for v in values:\n",
    "        total += v\n",
    "        n += 1\n",
    "    # varianza muestral\n",
    "    var = total / (n - 1)\n",
    "    context.write(\"desvio\", math.sqrt(var))\n",
    "\n",
    "# leer promedio del job_stats\n",
    "with open(statsDir + \"output.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "prom_line = [l for l in lines if l.startswith(\"promedio\")][0]\n",
    "promedio = float(prom_line.strip().split('\\t')[1])\n",
    "\n",
    "params = {\"avg\": promedio}\n",
    "job_desvio = Job(wcDir, desvioDir, fmap_desvio, fred_desvio)\n",
    "job_desvio.setParams(params)\n",
    "job_desvio.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcfe01d-a5b6-4ef3-920c-a150424e3608",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 4\n",
    "Utilice el dataset Libros para implementar una aplicación MapReduce que devuelva como salida todos los párrafos que tienen una longitud mayor al promedio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43b79a0-43be-4fbe-a111-97c57c349feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 13\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 321\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 337\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 599\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 33\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 112\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 177\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 64\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 457\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 269\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1 -> [13, 321, 337, 599, 33, 112, 177, 64, 457, 269, '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mpromedio\u001b[0m\t293.4931506849315\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m FRAY BALTASAR -> 13\n",
      "\u001b[94m[Map]\u001b[0m Cuando se hallÃ³, por fin, en la soledad del _Scriptorium_, tomÃ³ los pinceles con mano trÃ©mula y, sobre el estirado trozo de vitela, quiso reproducir una vez mÃ¡s las iluminaciones del misal del monasterio y del Libro de horas de la Reina de Francia; mas nada pudo lograr. Sus dibujos parecÃ­an los dibujos de un niÃ±o. -> 321\n",
      "\u001b[94m[Map]\u001b[0m Ninguno de los facultativos que consulté encontraba remedio a mi mal, y no puse término a mis días con mi propia mano, gracias a mis principios religiosos. Por fin, siguiendo el consejo de no recuerdo qué médico famoso, determiné que varios de los doctores más eminentes de la ciudad se reunieran en consulta, y después de dos horas del más penoso interrogatorio, pronunciaron mi sentencia. Mi mal era incurable y degeneraría en locura; el tumor que se habia formado en mi cerebro era inoperable y la muerte se aproximaba, aunque lentamente. -> 541\n",
      "\u001b[94m[Map]\u001b[0m Inútil me parece decir que la noticia de mi rápida curación se extendió por todo el país, y el nombre del Dr. Idiáquez en seguida se hizo célebre. De allí en adelante, efectuó las más sorprendentes curaciones, y al cabo de poco tiempo, reunió una fortuna considerable. Lo que más intrigaba a sus pacientes era que jamás recetaba, sino que él mismo proporcionaba las medicinas, marcándolas generalmente con letras, aunque a veces también con números. -> 449\n",
      "\u001b[94m[Map]\u001b[0m A pesar de la estrecha amistad que unía a los Hernández de Sandoval con mi familia, desde largos años, no había yo tenido ocasión de visitar ninguna de sus haciendas, aunque ellos sí habían pasado largas temporadas en la nuestra, situada en el centro del país; de manera que, en cuanto se ofreció la oportunidad de acompañar al hijo de la casa, Antonio, pudiendo desprenderme de mis no múltiples, pero sí imprescindibles quehaceres, la aproveché gustoso para ir en tan grata compañía a recorrer la finca principal de su casa, célebre por su riqueza y encantos naturales. -> 570\n",
      "\u001b[94m[Map]\u001b[0m A pesar del cansancio que sentía, permanecí no corto espacio de tiempo en la soledad de aquella galería, perdido en mis pensamientos, y con un leve zumbar de oídos, _oía el silencio_, que sólo interrumpía, de vez en cuando, el ladrar de un perro en el «real» no lejano. -> 269\n",
      "\u001b[94m[Map]\u001b[0m No viene al caso referir nuestra vida en aquella finca durante la semana que en ella pasamos; sólo diré que durante seis noches, y aproximadamente a la misma hora, se repitió el incidente de la primera, cosa que nos intrigó de tal modo, que nos propusimos descubrir al nocturno asmático. Juzgó Antonio lo más acertado ordenar a un tal Paulino, muy adicto suyo y hombre de toda confianza, que pasara la noche en mi estancia, en el umbral mismo de la puerta-ventana, para ayudar a aclarar el molesto, si bien un tanto ridículo misterio. -> 534\n",
      "\u001b[94m[Map]\u001b[0m Y le referí atropelladamente lo que acabábamos de oír. -> 54\n",
      "\u001b[94m[Map]\u001b[0m --Sígueme. -> 10\n",
      "\u001b[94m[Map]\u001b[0m Pasaron algunos meses. Un día me dijo Antonio: -> 46\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: *       *       *       *       * -> [33, 33, 33]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --\"Estimado Padre Rodríguez: Le ruego se sirva dar cristiana sepultura al portador de la presente. Su afmo. Hermano en Xto. _Alonso Hurtado, S.J._\" -> [147]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Amigo mío, ese es mi secreto; pero puesto que a usted le debo mi fortuna, se lo diré, si me promete, si me jura, no decirlo mientras yo viva. En cuanto muera, queda usted en libertad para proclamarlo a los cuatro vientos. -> [223]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Amigo, dijo el Padre Hurtado, en esta casa no tenemos jardín. -> [63]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Angustias, ¿Qué hacen los muertos de la capilla, en la noche? -> [63]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Aquí tienes, dijo Antonio, a la persona que prometí presentarte. Como ves, es una obra de arte. Se llama Herrera Goya. Para que no te rías de un miembro de la familia, te contaré que Don Joaquín de Herrera Goya fué antepasado mío, aunque no en línea recta, pues murió soltero; su hermana, mi cuarta abuela, heredó de él esta hacienda y no sé si a ella se deba tan hermosa estatua. Es costumbre pintarla cada año; así como hoy la ves color de rosa, ha estado pintada de celeste, amarillo, verde, de todo menos de negro, pues hay aquí la creencia,--cosas de los indios,--que si llegara a pintarse de ese color, ocurriría alguna desgracia. La postura de sus manos indica, no que va a aplaudir, sino que la distancia que con ellos mide es el tamaño de los panes de azúcar que en su hacienda se fabricaban y que llenaron sus bolsillos de doblones. La tradición no cuenta cosas muy halagadoras para este señor; te las referiré algún día. -> [933]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Aun vivo, Eminencia, repuso el Conde sonriendo, e hizo ademÃ¡n de besar la mano del Prelado, pero Ã©ste la retirÃ³ disimuladamente indicando con ella una butaca cercana. TomÃ³ asiento el Conde, y despuÃ©s de unos instantes de embarazoso silencio, dijo: -> [254]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Buenas tardes, Padre, contestó Juan González, con el rostro iluminado por la esperanza. -> [89]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Buenas tardes. -> [16]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Buenos días, Padre. -> [21]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t*       *       *       *       *\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t*       *       *       *       *\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t*       *       *       *       *\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--\"Estimado Padre Rodríguez: Le ruego se sirva dar cristiana sepultura al portador de la presente. Su afmo. Hermano en Xto. _Alonso Hurtado, S.J._\"\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Amigo mío, ese es mi secreto; pero puesto que a usted le debo mi fortuna, se lo diré, si me promete, si me jura, no decirlo mientras yo viva. En cuanto muera, queda usted en libertad para proclamarlo a los cuatro vientos.\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Amigo, dijo el Padre Hurtado, en esta casa no tenemos jardín.\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Angustias, ¿Qué hacen los muertos de la capilla, en la noche?\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Aquí tienes, dijo Antonio, a la persona que prometí presentarte. Como ves, es una obra de arte. Se llama Herrera Goya. Para que no te rías de un miembro de la familia, te contaré que Don Joaquín de Herrera Goya fué antepasado mío, aunque no en línea recta, pues murió soltero; su hermana, mi cuarta abuela, heredó de él esta hacienda y no sé si a ella se deba tan hermosa estatua. Es costumbre pintarla cada año; así como hoy la ves color de rosa, ha estado pintada de celeste, amarillo, verde, de todo menos de negro, pues hay aquí la creencia,--cosas de los indios,--que si llegara a pintarse de ese color, ocurriría alguna desgracia. La postura de sus manos indica, no que va a aplaudir, sino que la distancia que con ellos mide es el tamaño de los panes de azúcar que en su hacienda se fabricaban y que llenaron sus bolsillos de doblones. La tradición no cuenta cosas muy halagadoras para este señor; te las referiré algún día.\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Aun vivo, Eminencia, repuso el Conde sonriendo, e hizo ademÃ¡n de besar la mano del Prelado, pero Ã©ste la retirÃ³ disimuladamente indicando con ella una butaca cercana. TomÃ³ asiento el Conde, y despuÃ©s de unos instantes de embarazoso silencio, dijo:\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Buenas tardes, Padre, contestó Juan González, con el rostro iluminado por la esperanza.\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, math\n",
    "sys.path.append(\"..\")\n",
    "from MRE import Job\n",
    "\n",
    "librosDir = \"./practica_2_hadoop_mapReduce/Libros/input\"\n",
    "out1Dir = \"./practica_2_hadoop_mapReduce/Libros/ej4_out1/\"\n",
    "\n",
    "# ===== Job 1: promedio de longitud de párrafos =====\n",
    "def fmap_len(key, value, context):\n",
    "    length = len(value.strip())\n",
    "    context.write(1, length)\n",
    "\n",
    "def fred_len(key, values, context):\n",
    "    total, n = 0, 0\n",
    "    for v in values:\n",
    "        total += v\n",
    "        n += 1\n",
    "    avg = total / n if n > 0 else 0\n",
    "    context.write(\"promedio\", avg)\n",
    "\n",
    "job1 = Job(librosDir, out1Dir, fmap_len, fred_len)\n",
    "job1.waitForCompletion()\n",
    "\n",
    "out2Dir = \"./Libros/ej4_out2/\"\n",
    "\n",
    "# ===== Job 2: filtrar párrafos mayores al promedio =====\n",
    "def fmap_filter(key, value, context):\n",
    "    length = len(value.strip())\n",
    "    context.write(value.strip(), length)\n",
    "\n",
    "def fred_filter(parrafo, values, context):\n",
    "    avg = context[\"avg\"]\n",
    "    for v in values:\n",
    "        if v > avg:\n",
    "            context.write(\"Párrafo > promedio\", parrafo)\n",
    "\n",
    "params = {\"avg\": promedio}\n",
    "job2 = Job(librosDir, out2Dir, fmap_filter, fred_filter)\n",
    "job2.setParams(params)\n",
    "job2.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec15c4b-9c10-4632-a7a2-fd92672b0ec2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 5\n",
    "\n",
    "El dataset website tiene información sobre el tiempo de permanencia de sus usuarios\n",
    "en cada una de las páginas del sitio. El formato de los datos del dataset es:\n",
    "<id_user, id_page, time>\n",
    "Implemente una aplicación MapReduce, utilizando combiners en los casos que\n",
    "considere necesario, que calcule\n",
    "\n",
    "> Indique como queda el DAG del proceso completo (las tres consultas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723344e-ca9b-45bb-9ace-f13c21f96808",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### a. La página más visitada (la página en la que más tiempo permaneció) para cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cecff47-6285-4ecd-948b-4ff5c26a878b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m ('9697', '1539') -> 79\n",
      "\u001b[94m[Map]\u001b[0m ('11421', '1470') -> 5\n",
      "\u001b[94m[Map]\u001b[0m ('11071', '2454') -> 94\n",
      "\u001b[94m[Map]\u001b[0m ('11645', '2407') -> 35\n",
      "\u001b[94m[Map]\u001b[0m ('11294', '1352') -> 16\n",
      "\u001b[94m[Map]\u001b[0m ('13592', '1645') -> 2\n",
      "\u001b[94m[Map]\u001b[0m ('13346', '2318') -> 29\n",
      "\u001b[94m[Map]\u001b[0m ('9068', '2015') -> 78\n",
      "\u001b[94m[Map]\u001b[0m ('14963', '1227') -> 74\n",
      "\u001b[94m[Map]\u001b[0m ('12846', '3144') -> 34\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10000', '2332') -> [81]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10000', '2852') -> [52]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10001', '2903') -> [82]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10002', '1353') -> [27]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10002', '2699') -> [24]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10004', '3676') -> [30]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10005', '3079') -> [21]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10007', '1084') -> [6]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10007', '3095') -> [65]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10008', '1986') -> [6]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m('10000', '2332')\u001b[0m\t81\n",
      "\u001b[95m('10000', '2852')\u001b[0m\t52\n",
      "\u001b[95m('10001', '2903')\u001b[0m\t82\n",
      "\u001b[95m('10002', '1353')\u001b[0m\t27\n",
      "\u001b[95m('10002', '2699')\u001b[0m\t24\n",
      "\u001b[95m('10004', '3676')\u001b[0m\t30\n",
      "\u001b[95m('10005', '3079')\u001b[0m\t21\n",
      "\u001b[95m('10007', '1084')\u001b[0m\t6\n",
      "\u001b[95m('10007', '3095')\u001b[0m\t65\n",
      "\u001b[95m('10008', '1986')\u001b[0m\t6\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 10000 -> ('2332', 81)\n",
      "\u001b[94m[Map]\u001b[0m 10008 -> ('2693', 34)\n",
      "\u001b[94m[Map]\u001b[0m 10024 -> ('2491', 95)\n",
      "\u001b[94m[Map]\u001b[0m 10032 -> ('3077', 13)\n",
      "\u001b[94m[Map]\u001b[0m 10045 -> ('2016', 19)\n",
      "\u001b[94m[Map]\u001b[0m 10060 -> ('2797', 3)\n",
      "\u001b[94m[Map]\u001b[0m 10070 -> ('1194', 3)\n",
      "\u001b[94m[Map]\u001b[0m 10080 -> ('1724', 92)\n",
      "\u001b[94m[Map]\u001b[0m 10092 -> ('3902', 46)\n",
      "\u001b[94m[Map]\u001b[0m 10105 -> ('1291', 32)\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10000 -> [('2332', 81), ('2852', 52)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10001 -> [('2903', 82)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10002 -> [('1353', 27), ('2699', 24)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10004 -> [('3676', 30)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10005 -> [('3079', 21)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10007 -> [('1084', 6), ('3095', 65)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10008 -> [('2693', 34), ('1986', 6)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10009 -> [('1586', 48), ('3638', 9), ('3926', 63)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10011 -> [('2720', 71)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10012 -> [('3152', 67)]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m10000\u001b[0m\t2332\n",
      "\u001b[95m10001\u001b[0m\t2903\n",
      "\u001b[95m10002\u001b[0m\t1353\n",
      "\u001b[95m10004\u001b[0m\t3676\n",
      "\u001b[95m10005\u001b[0m\t3079\n",
      "\u001b[95m10007\u001b[0m\t3095\n",
      "\u001b[95m10008\u001b[0m\t2693\n",
      "\u001b[95m10009\u001b[0m\t3926\n",
      "\u001b[95m10011\u001b[0m\t2720\n",
      "\u001b[95m10012\u001b[0m\t3152\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from MRE import Job\n",
    "\n",
    "# directorios de trabajo\n",
    "inputDir = \"./practica_2_hadoop_mapReduce/website/input/\"\n",
    "out1 = \"./practica_2_hadoop_mapReduce/website/out_A1/\"\n",
    "out2 = \"./practica_2_hadoop_mapReduce/website/out_A2/\"\n",
    "\n",
    "# agrupa por (user, page)\n",
    "def fmap_1(user_id, value, context):\n",
    "    parts = value.strip().split('\\t')\n",
    "    page_id, time = parts\n",
    "    context.write((user_id, page_id), int(time))\n",
    "\n",
    "# reduce: suma tiempos por (user, page)\n",
    "def fred_1(key, values, context):\n",
    "    total_time = 0\n",
    "    for t in values:\n",
    "        total_time += t\n",
    "    context.write(key, total_time)\n",
    "\n",
    "# agrupa por user\n",
    "def fmap_2(user_id, value, context):\n",
    "    parts = value.strip().split('\\t')\n",
    "    page_id, total_time = parts\n",
    "    context.write(user_id, (page_id, int(total_time)))\n",
    "\n",
    "# reduce: selecciona la página con más tiempo\n",
    "def fred_2(user_id, values, context):\n",
    "    max_time = -1\n",
    "    best_page = None\n",
    "    for page_id, t in values:\n",
    "        if t > max_time:\n",
    "            max_time = t\n",
    "            best_page = page_id\n",
    "    context.write(user_id, best_page)\n",
    "\n",
    "job1 = Job(inputDir, out1, fmap_1, fred_1)\n",
    "job1.setCombiner(fred_1)\n",
    "job1.waitForCompletion()\n",
    "\n",
    "job2 = Job(out1, out2, fmap_2, fred_2)\n",
    "job2.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c7a132-a434-4ebe-a719-6483a1b82680",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### b. El usuario que más páginas distintas visitó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92136928-4243-49eb-a423-4073181ff086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 10000 -> 2332\n",
      "\u001b[94m[Map]\u001b[0m 10008 -> 2693\n",
      "\u001b[94m[Map]\u001b[0m 10024 -> 2491\n",
      "\u001b[94m[Map]\u001b[0m 10032 -> 3077\n",
      "\u001b[94m[Map]\u001b[0m 10045 -> 2016\n",
      "\u001b[94m[Map]\u001b[0m 10060 -> 2797\n",
      "\u001b[94m[Map]\u001b[0m 10070 -> 1194\n",
      "\u001b[94m[Map]\u001b[0m 10080 -> 1724\n",
      "\u001b[94m[Map]\u001b[0m 10092 -> 3902\n",
      "\u001b[94m[Map]\u001b[0m 10105 -> 1291\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10000 -> ['2332', '2852']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10001 -> ['2903']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10002 -> ['1353', '2699']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10004 -> ['3676']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10005 -> ['3079']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10007 -> ['1084', '3095']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10008 -> ['2693', '1986']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10009 -> ['1586', '3638', '3926']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10011 -> ['2720']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10012 -> ['3152']\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m10000\u001b[0m\t2\n",
      "\u001b[95m10001\u001b[0m\t1\n",
      "\u001b[95m10002\u001b[0m\t2\n",
      "\u001b[95m10004\u001b[0m\t1\n",
      "\u001b[95m10005\u001b[0m\t1\n",
      "\u001b[95m10007\u001b[0m\t2\n",
      "\u001b[95m10008\u001b[0m\t2\n",
      "\u001b[95m10009\u001b[0m\t3\n",
      "\u001b[95m10011\u001b[0m\t1\n",
      "\u001b[95m10012\u001b[0m\t1\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10000', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10013', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10036', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10054', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10070', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10090', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10110', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10125', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10143', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10167', 1)\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1 -> [('10000', 2), ('10013', 1), ('10036', 2), ('10054', 3), ('10070', 2), ('10090', 1), ('10110', 1), ('10125', 1), ('10143', 1), ('10167', 1), '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mUsuario con más páginas distintas\u001b[0m\t('9458', 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directorios de salida para inciso B\n",
    "out3 = \"./practica_2_hadoop_mapReduce/website/out_B1/\"\n",
    "out4 = \"./practica_2_hadoop_mapReduce/website/out_B2/\"\n",
    "\n",
    "# cuenta páginas distintas por usuario\n",
    "def fmap_3(user_id, value, context):\n",
    "    parts = value.strip().split('\\t')\n",
    "    page_id, _ = parts\n",
    "    context.write(user_id, page_id)\n",
    "\n",
    "def fred_3(user_id, values, context):\n",
    "    distinct_pages = set(values)\n",
    "    context.write(user_id, len(distinct_pages))\n",
    "\n",
    "# agrupa todos los (user, count) bajo una misma clave\n",
    "def fmap_4(user_id, value, context):\n",
    "    context.write(1, (user_id, int(value.strip())))\n",
    "\n",
    "def fred_max(_, values, context):\n",
    "    best_user, max_count = None, -1\n",
    "    for user, c in values:\n",
    "        if c > max_count:\n",
    "            max_count = c\n",
    "            best_user = user\n",
    "    context.write(\"Usuario con más páginas distintas\", (best_user, max_count))\n",
    "\n",
    "job3 = Job(out1, out3, fmap_3, fred_3)\n",
    "job3.waitForCompletion()\n",
    "\n",
    "job4 = Job(out3, out4, fmap_4, fred_max)\n",
    "job4.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c7dc4-a7dd-414f-b647-4eb6000d7b54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### c. La página más visitada (en cuanto a cantidad de visitas, sin importar el tiempo de permanencia) por todos los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f8ffa30-b569-4cc8-a746-683c5056a84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1071 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3188 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3401 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 2326 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 2394 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3614 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1532 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 2813 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3916 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3869 -> 1\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1000 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1001 -> [1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1002 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1003 -> [1, 1, 1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1005 -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1006 -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1007 -> [1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1008 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1010 -> [1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1011 -> [1, 1]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m1000\u001b[0m\t1\n",
      "\u001b[95m1001\u001b[0m\t3\n",
      "\u001b[95m1002\u001b[0m\t1\n",
      "\u001b[95m1003\u001b[0m\t5\n",
      "\u001b[95m1005\u001b[0m\t2\n",
      "\u001b[95m1006\u001b[0m\t2\n",
      "\u001b[95m1007\u001b[0m\t3\n",
      "\u001b[95m1008\u001b[0m\t1\n",
      "\u001b[95m1010\u001b[0m\t3\n",
      "\u001b[95m1011\u001b[0m\t2\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1000 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1012 -> 3\n",
      "\u001b[94m[Map]\u001b[0m 1025 -> 2\n",
      "\u001b[94m[Map]\u001b[0m 1036 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1047 -> 3\n",
      "\u001b[94m[Map]\u001b[0m 1058 -> 2\n",
      "\u001b[94m[Map]\u001b[0m 1073 -> 2\n",
      "\u001b[94m[Map]\u001b[0m 1085 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1096 -> 3\n",
      "\u001b[94m[Map]\u001b[0m 1107 -> 2\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1000 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1001 -> [3]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1002 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1003 -> [5]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1005 -> [2]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1006 -> [2]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1007 -> [3]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1008 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1010 -> [3]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1011 -> [2]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m1000\u001b[0m\t1\n",
      "\u001b[95m1001\u001b[0m\t3\n",
      "\u001b[95m1002\u001b[0m\t1\n",
      "\u001b[95m1003\u001b[0m\t5\n",
      "\u001b[95m1005\u001b[0m\t2\n",
      "\u001b[95m1006\u001b[0m\t2\n",
      "\u001b[95m1007\u001b[0m\t3\n",
      "\u001b[95m1008\u001b[0m\t1\n",
      "\u001b[95m1010\u001b[0m\t3\n",
      "\u001b[95m1011\u001b[0m\t2\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1000', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1012', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1025', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1036', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1047', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1058', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1073', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1085', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1096', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1107', 2)\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1 -> [('1000', 1), ('1012', 3), ('1025', 2), ('1036', 1), ('1047', 3), ('1058', 2), ('1073', 2), ('1085', 1), ('1096', 3), ('1107', 2), '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mPágina más visitada\u001b[0m\t('1694', 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directorios de salida para inciso C\n",
    "out5 = \"./practica_2_hadoop_mapReduce/website/out_C1/\"\n",
    "out6 = \"./practica_2_hadoop_mapReduce/website/out_C2/\"\n",
    "out7 = \"./practica_2_hadoop_mapReduce/website/out_C3/\"\n",
    "\n",
    "# ---------------- JOB 5 ----------------\n",
    "# Emite (page_id, 1) por cada visita\n",
    "def fmap_5(user_id, value, context):\n",
    "    parts = value.strip().split('\\t') \n",
    "    page_id, time = parts   # el tiempo no importa acá\n",
    "    context.write(page_id, 1)\n",
    "\n",
    "def fred_count(page_id, values, context):\n",
    "    total_visits = sum(values)\n",
    "    context.write(page_id, total_visits)\n",
    "\n",
    "# ---------------- JOB 6 ----------------\n",
    "# Junta todas las visitas de cada página (ya están como enteros)\n",
    "def fmap_6(page_id, value, context):\n",
    "    context.write(page_id, int(value.strip()))\n",
    "\n",
    "def fred_sum(page_id, values, context):\n",
    "    total = sum(values)\n",
    "    context.write(page_id, total)\n",
    "\n",
    "# ---------------- JOB 7 ----------------\n",
    "# Busca la página con más visitas\n",
    "def fmap_7(page_id, value, context):\n",
    "    context.write(1, (page_id, int(value.strip())))\n",
    "\n",
    "def fred_max(_, values, context):\n",
    "    max_count = -1\n",
    "    best_page = None\n",
    "    for page, count in values:\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            best_page = page\n",
    "    context.write(\"Página más visitada\", (best_page, max_count))\n",
    "\n",
    "job5 = Job(inputDir, out5, fmap_5, fred_count)\n",
    "job5.waitForCompletion()\n",
    "\n",
    "job6 = Job(out5, out6, fmap_6, fred_sum)\n",
    "job6.waitForCompletion()\n",
    "\n",
    "job7 = Job(out6, out7, fmap_7, fred_max)\n",
    "job7.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0d5ca-3366-409a-a318-f5c209773fca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6) Cómo plantearía una solución MapReduce a los siguientes algoritmos secuenciales:\n",
    "\n",
    "i. entrada\n",
    "\n",
    "```\n",
    "textos: array [1..N] of string (dataset libros)\n",
    "```\n",
    "ii. algoritmo\n",
    "\n",
    "```python\n",
    "a={}; b={}; N = len(textos)\n",
    "for l in textos:\n",
    "    words = l.split()\n",
    "    for w in words:\n",
    "        a[w] = a[w]+1\n",
    "\n",
    "for w in a.keys():\n",
    "    for l in lines:\n",
    "        words = l.split()\n",
    "        if w in words:\n",
    "            b[w]=b[w]+1\n",
    "for k in a.keys():\n",
    "    print(k + \" = \" + str(a[w] * (N / b[w])))\n",
    "```\n",
    "\n",
    "El algoritmo secuencial trabaja como una variante de **TF-IDF** (frecuencia de palabra por documento).\n",
    "Hace tres cosas:\n",
    "\n",
    "1. Cuenta cuántas veces aparece cada palabra en todo el dataset (`a[w]`).\n",
    "2. Cuenta en cuántos documentos (líneas o párrafos) aparece cada palabra (`b[w]`).\n",
    "3. Devuelve para cada palabra: `a[w] * (N / b[w])`, donde `N` es la cantidad total de documentos.\n",
    "\n",
    "**Cómo se plantea en MapReduce**\n",
    "\n",
    "Este problema no se resuelve con un solo job, sino con **tres jobs encadenados**:\n",
    "\n",
    "* **Job 1 (contar ocurrencias totales de palabras):**\n",
    "\n",
    "  * *Map:* cada mapper toma un documento y por cada palabra emite `(palabra, 1)`.\n",
    "  * *Reduce:* los reducers suman esos 1 y obtienen cuántas veces aparece cada palabra en todo el dataset.\n",
    "  * **Salida:** `(palabra, total_ocurrencias)` → esto es `a[w]`.\n",
    "\n",
    "* **Job 2 (contar en cuántos documentos aparece cada palabra):**\n",
    "\n",
    "  * *Map:* cada mapper toma un documento y por cada palabra distinta en ese documento emite `(palabra, doc_id)`.\n",
    "  * *Reduce:* para cada palabra, cuenta la cantidad de `doc_id` distintos → en cuántos documentos aparece.\n",
    "  * **Salida:** `(palabra, num_docs)` → esto es `b[w]`.\n",
    "\n",
    "* **Job 3 (cálculo final):**\n",
    "\n",
    "  * *Map:* se unen las salidas de Job1 y Job2 por clave (la palabra).\n",
    "  * *Reduce:* con `a[w]` y `b[w]` calcula `a[w] * (N / b[w])`.\n",
    "  * **Salida final:** `(palabra, score)`.\n",
    "\n",
    "🔗 El **DAG** se ve así:\n",
    "\n",
    "```\n",
    "Dataset Libros\n",
    " ├─ Job1 → a[w] = total ocurrencias\n",
    " ├─ Job2 → b[w] = nº de documentos con w\n",
    " └─ Job3 (join y cálculo) → resultado final\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "b.\n",
    "i. entrada\n",
    "```\n",
    "datos: array [1..N] of /<int1, int2, ..., intM> (todos los valores están dentro de un rango de valores conocido, para poder usarlos como índices del tensor)\n",
    "```\n",
    "ii. algoritmo\n",
    "\n",
    "```python\n",
    "for t in datos:\n",
    "    v = t.split(\"\\t\")\n",
    "    c = v[-1]\n",
    "        for a in range(len(v)-1):\n",
    "        x= v[a]\n",
    "        m[a][x][c] = m[a][x][c] + 1\n",
    "\n",
    "max=[[0,0,0], [0,0,0]]\n",
    "for x in range(len(m)):\n",
    "    for y in range(len(m[0])):\n",
    "        for z in range(2):\n",
    "            if(m[x][y][z] > max[z][0]):\n",
    "                max[z][0] = m[x][y][z]\n",
    "                max[z][1]=x\n",
    "                max[z][2]=y\n",
    "\n",
    "for z in range(2):\n",
    "    print(z +\";\" + max[z][1] +\";\" + max[z][2])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "El algoritmo secuencial toma un dataset de tuplas `<x1, x2, …, xM, c>` (atributos + clase).\n",
    "Hace dos cosas:\n",
    "\n",
    "1. Construye una especie de “tensor de frecuencias” `m[a][x][c]`, que cuenta cuántas veces el atributo `a` tomó el valor `x` en ejemplos de clase `c`.\n",
    "2. Busca, para cada clase `c`, cuál es el valor de atributo que más se repite.\n",
    "\n",
    "**Cómo se plantea en MapReduce**\n",
    "\n",
    "Este problema se resuelve en **dos jobs**:\n",
    "\n",
    "* **Job 1 (conteo de triples atributo–valor–clase):**\n",
    "\n",
    "  * *Map:* para cada tupla `<x1, …, xM, c>`, emite `(a, x, c) → 1` para cada atributo `a` y su valor `x`.\n",
    "  * *Reduce:* para cada triple `(a, x, c)` suma todas las ocurrencias.\n",
    "  * **Salida:** `(a, x, c, count)` → cuántas veces apareció el valor `x` del atributo `a` en la clase `c`.\n",
    "\n",
    "* **Job 2 (buscar máximos por clase):**\n",
    "\n",
    "  * *Map:* reemite los resultados del Job 1 pero agrupando por clase `c`.\n",
    "  * *Reduce:* para cada clase `c`, recorre todos los `(a, x, count)` y selecciona el de mayor frecuencia.\n",
    "  * **Salida final:** `(c, mejor atributo=a, valor=x, count)`.\n",
    "\n",
    "🔗 El **DAG** se ve así:\n",
    "\n",
    "```\n",
    "Dataset Datos\n",
    " ├─ Job1 → conteo de (atributo, valor, clase)\n",
    " └─ Job2 → selección del máximo por clase\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f6aa4-cfd5-4146-b041-28fdc562dfac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
