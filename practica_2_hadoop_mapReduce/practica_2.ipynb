{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fc5fe6-6e5d-48b6-bad8-cecc1a2d459e",
   "metadata": {},
   "source": [
    "<div align='center'>\n",
    "\n",
    "# Practica 2\n",
    "\n",
    "<img src='https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExbXVoOXh6bGtwend4cW5majMwZHRiYzh6b2loZGNseGZmajMxbmhsNiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/aMwdfGSyeYjUKY6vjf/giphy.gif'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318478e-c2e9-49ab-a66d-ad6d3a8f6486",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 1)\n",
    "¿En el dataset del ejercicio 1 de la práctica 1 indique para cada Job, si se vería beneficiado por una función combiner?\n",
    "\n",
    "En caso afirmativo,\n",
    "\n",
    "¿cuál es la implementación de dicha función? ¿Qué datos recibe cada reduce, al utilizar la función combiner?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ca962-7047-420f-aa38-ada70ee73fb0",
   "metadata": {},
   "source": [
    "## Ejercicio 2)\n",
    "Implemente una función combiner para el problema del WordCount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862c096a-e224-4355-a583-e3a60a91c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m ï»¿LA -> 1\n",
      "\u001b[94m[Map]\u001b[0m PUERTA -> 1\n",
      "\u001b[94m[Map]\u001b[0m DE -> 1\n",
      "\u001b[94m[Map]\u001b[0m BRONCE -> 1\n",
      "\u001b[94m[Map]\u001b[0m --Â¡Adelante! -> 1\n",
      "\u001b[94m[Map]\u001b[0m exclamÃ³ -> 1\n",
      "\u001b[94m[Map]\u001b[0m el -> 1\n",
      "\u001b[94m[Map]\u001b[0m Prelado, -> 1\n",
      "\u001b[94m[Map]\u001b[0m y -> 1\n",
      "\u001b[94m[Map]\u001b[0m apareciÃ³ -> 1\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: !ah! -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"A\" -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"B\" -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"Dr. -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"El -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: \"purgar\", -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: (aquÃ­ -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: (con -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: (naturalmente) -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: * -> [11, 1, 1, 1, 1]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m!ah!\u001b[0m\t1\n",
      "\u001b[95m\"A\"\u001b[0m\t1\n",
      "\u001b[95m\"B\"\u001b[0m\t1\n",
      "\u001b[95m\"Dr.\u001b[0m\t1\n",
      "\u001b[95m\"El\u001b[0m\t1\n",
      "\u001b[95m\"purgar\",\u001b[0m\t1\n",
      "\u001b[95m(aquÃ­\u001b[0m\t1\n",
      "\u001b[95m(con\u001b[0m\t1\n",
      "\u001b[95m(naturalmente)\u001b[0m\t1\n",
      "\u001b[95m*\u001b[0m\t5\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from MRE import Job\n",
    "\n",
    "inputDir = \"./WordCount/input/\"\n",
    "outputDir = \"./WordCount/ejercicio_2/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    words = value.split()\n",
    "    for w in words:\n",
    "        context.write(w, 1)\n",
    "        \n",
    "def fred(key, values, context):\n",
    "    c=0\n",
    "    for v in values:\n",
    "        c=c+1\n",
    "    context.write(key, c)\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "job.setCombiner(fred)\n",
    "success = job.waitForCompletion()\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209636de-177f-4293-91f8-a2f53e096e3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 3)\n",
    "Implemente un job MapReduce para calcular el máximo, mínimo, promedio y desvío stándard de las ocurrencias de todas las palabras del dataset Libros.\n",
    "\n",
    "#### Cuenta ocurrencias de cada palabra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac60f1c-c5c4-4a5b-972a-c191e92c6b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m fray -> 1\n",
      "\u001b[94m[Map]\u001b[0m baltasar -> 1\n",
      "\u001b[94m[Map]\u001b[0m cuando -> 1\n",
      "\u001b[94m[Map]\u001b[0m se -> 1\n",
      "\u001b[94m[Map]\u001b[0m hallã³ -> 1\n",
      "\u001b[94m[Map]\u001b[0m por -> 1\n",
      "\u001b[94m[Map]\u001b[0m fin -> 1\n",
      "\u001b[94m[Map]\u001b[0m en -> 1\n",
      "\u001b[94m[Map]\u001b[0m la -> 1\n",
      "\u001b[94m[Map]\u001b[0m soledad -> 1\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: * -> [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, '...']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --\"estimado -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --amigo -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --angustias -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --aquí -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --aun -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --buenas -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --buenos -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --comprendo -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --doctor -> [1]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m*\u001b[0m\t15\n",
      "\u001b[95m--\"estimado\u001b[0m\t1\n",
      "\u001b[95m--amigo\u001b[0m\t2\n",
      "\u001b[95m--angustias\u001b[0m\t1\n",
      "\u001b[95m--aquí\u001b[0m\t1\n",
      "\u001b[95m--aun\u001b[0m\t1\n",
      "\u001b[95m--buenas\u001b[0m\t2\n",
      "\u001b[95m--buenos\u001b[0m\t2\n",
      "\u001b[95m--comprendo\u001b[0m\t1\n",
      "\u001b[95m--doctor\u001b[0m\t1\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from MRE import Job\n",
    "\n",
    "inputDir = \"./Libros/input\"\n",
    "wcDir = \"./Libros/ej3_wc/\"\n",
    "\n",
    "def fmap_wc(key, value, context):\n",
    "    # separar por espacios\n",
    "    for palabra in value.strip().split():\n",
    "        palabra = palabra.lower().strip(\".,;:¡!¿?\\\"()[]\")\n",
    "        if palabra:\n",
    "            context.write(palabra, 1)\n",
    "\n",
    "def fred_wc(key, values, context):\n",
    "    total = 0\n",
    "    for v in values:\n",
    "        total += v\n",
    "    context.write(key, total)\n",
    "\n",
    "job_wc = Job(inputDir, wcDir, fmap_wc, fred_wc)\n",
    "job_wc.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbd28d-0c99-4203-8e2f-e66d8c5cd8a3",
   "metadata": {},
   "source": [
    "#### Job de estadísticas (min, max, promedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e90ef1ab-d50d-4cee-bd99-d36ba947177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m min -> 15\n",
      "\u001b[94m[Map]\u001b[0m max -> 15\n",
      "\u001b[94m[Map]\u001b[0m avg -> 15\n",
      "\u001b[94m[Map]\u001b[0m min -> 1\n",
      "\u001b[94m[Map]\u001b[0m max -> 1\n",
      "\u001b[94m[Map]\u001b[0m avg -> 1\n",
      "\u001b[94m[Map]\u001b[0m min -> 1\n",
      "\u001b[94m[Map]\u001b[0m max -> 1\n",
      "\u001b[94m[Map]\u001b[0m avg -> 1\n",
      "\u001b[94m[Map]\u001b[0m min -> 1\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: avg -> [15, 1, 1, 1, 1, 1, 1, 1, 1, 3, '...']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: max -> [15, 1, 1, 1, 1, 1, 1, 1, 1, 3, '...']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: min -> [15, 1, 1, 1, 1, 1, 1, 1, 1, 3, '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mpromedio\u001b[0m\t3.4946911196911197\n",
      "\u001b[95mmax\u001b[0m\t839\n",
      "\u001b[95mmin\u001b[0m\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsDir = \"./Libros/ej3_stats/\"\n",
    "\n",
    "def fmap_stats(key, value, context):\n",
    "    ocurr = int(value.strip())\n",
    "    context.write(\"min\", ocurr)\n",
    "    context.write(\"max\", ocurr)\n",
    "    context.write(\"avg\", ocurr)\n",
    "\n",
    "def fred_stats(key, values, context):\n",
    "    if key == \"min\":\n",
    "        context.write(\"min\", min(values))\n",
    "    elif key == \"max\":\n",
    "        context.write(\"max\", max(values))\n",
    "    elif key == \"avg\":\n",
    "        total, n = 0, 0\n",
    "        for v in values:\n",
    "            total += v\n",
    "            n += 1\n",
    "        context.write(\"promedio\", total / n)\n",
    "\n",
    "job_stats = Job(wcDir, statsDir, fmap_stats, fred_stats)\n",
    "job_stats.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efaeab3-7370-4c65-b20f-cc095789f4d2",
   "metadata": {},
   "source": [
    "#### Job de desvío estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b44229-6789-4562-9843-22183b597ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m var -> 132.3721324313144\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 6.223483782665732\n",
      "\u001b[94m[Map]\u001b[0m var -> 0.24471930390125368\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: var -> [132.3721324313144, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 6.223483782665732, 0.24471930390125368, '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mdesvio\u001b[0m\t22.917022729315015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desvioDir = \"./Libros/ej3_desvio/\"\n",
    "\n",
    "import math\n",
    "\n",
    "def fmap_desvio(key, value, context):\n",
    "    ocurr = int(value.strip())\n",
    "    avg = context[\"avg\"]\n",
    "    context.write(\"var\", (ocurr - avg) ** 2)\n",
    "\n",
    "def fred_desvio(key, values, context):\n",
    "    total, n = 0, 0\n",
    "    for v in values:\n",
    "        total += v\n",
    "        n += 1\n",
    "    # varianza muestral\n",
    "    var = total / (n - 1)\n",
    "    context.write(\"desvio\", math.sqrt(var))\n",
    "\n",
    "# leer promedio del job_stats\n",
    "with open(statsDir + \"output.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "prom_line = [l for l in lines if l.startswith(\"promedio\")][0]\n",
    "promedio = float(prom_line.strip().split('\\t')[1])\n",
    "\n",
    "params = {\"avg\": promedio}\n",
    "job_desvio = Job(wcDir, desvioDir, fmap_desvio, fred_desvio)\n",
    "job_desvio.setParams(params)\n",
    "job_desvio.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcfe01d-a5b6-4ef3-920c-a150424e3608",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 4\n",
    "Utilice el dataset Libros para implementar una aplicación MapReduce que devuelva como salida todos los párrafos que tienen una longitud mayor al promedio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43b79a0-43be-4fbe-a111-97c57c349feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 8\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 143\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 218\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 379\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 166\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 185\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 484\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 245\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 301\n",
      "\u001b[94m[Map]\u001b[0m 1 -> 46\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1 -> [8, 143, 218, 379, 166, 185, 484, 245, 301, 46, '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mpromedio\u001b[0m\t293.4931506849315\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m EL PAPAGAYO DE HUICHILOBOS -> 26\n",
      "\u001b[94m[Map]\u001b[0m Repentinamente oí una exclamación de sorpresa y, volviendo el rostro, me encontré cara a cara con el Padre Montero, mi antiguo condiscípulo, a quien no había visto en cinco años. Fungía de Sacristán mayor de la Catedral y llevaba un manojo de enormes llaves, pues era hora de cerrar el templo, para volver a abrirlo a las tres de la tarde. Inútil me parece relatar el gusto que me dió volver a ver a tan buen amigo mío. Convidóme a almorzar y prometió enseñarme él mismo, después, las mil maravillas que poseía aquel cabildo y que raras veces se exponían al público. -> 566\n",
      "\u001b[94m[Map]\u001b[0m *       *       *       *       * -> 33\n",
      "\u001b[94m[Map]\u001b[0m --Eso no sería fácil en tan corto espacio de tiempo. Lo que quiero contarte, puesto que confío en tu discreción, es lo siguiente: Has de saber que Su Eminencia, que es hombre activo, envió ayer mismo un mensaje a la Corte, para que viniese en seguida uno de los mejores joyeros y restaurase cuanto antes el desperfecto causado al papagayo. Llegó en el tren del medio día y el Deán, el Tesorero y yo hemos ido esta tarde a recoger la joya para entregársela; pero, calcula ¡cuál sería nuestra sorpresa, al abrir el cofre y ver que el papagayo ha desaparecido! Cómo ha podido llegar hasta allí el ladrón, nadie ha podido explicárselo. -> 631\n",
      "\u001b[94m[Map]\u001b[0m El reino se componía, además de la populosa ciudad de Tibotú, de dos islas. En una se cosechaba gran cantidad de café y había numerosas vacas de ordeña; en la otra se producía el cacao y habia muy buenos panaderos y reposteros. Las islas eran vulgarmente conocidas por «La-isla-de-café-con-leche», y «La-isla-de-chocolate-con-bollos». -> 334\n",
      "\u001b[94m[Map]\u001b[0m Comprendo que ustedes los reporteros tengan deberes para con sus lectores y que, por lo tanto anden siempre a caza de noticias; pero, como soy enemigo de repeticiones, quiero que el diario que usted representa, por ser el de mayor importancia en el paÃ­s, sea mi Ãºnico portavoz en este asunto. Dentro de diez minutos llegarÃ¡ mi mujer; mientras tanto, pues, le suplico que escuche con atenciÃ³n y escriba a mi dictado. Yo le darÃ© todos los pormenores del caso, que como verÃ¡, es cosa bien sencilla. -> 501\n",
      "\u001b[94m[Map]\u001b[0m FRAY BALTASAR -> 13\n",
      "\u001b[94m[Map]\u001b[0m Cuando se hallÃ³, por fin, en la soledad del _Scriptorium_, tomÃ³ los pinceles con mano trÃ©mula y, sobre el estirado trozo de vitela, quiso reproducir una vez mÃ¡s las iluminaciones del misal del monasterio y del Libro de horas de la Reina de Francia; mas nada pudo lograr. Sus dibujos parecÃ­an los dibujos de un niÃ±o. -> 321\n",
      "\u001b[94m[Map]\u001b[0m --¡Está llorando! -> 17\n",
      "\u001b[94m[Map]\u001b[0m Sentado en un amplio sillÃ³n de velludo carmesÃ­, al lado de ancha ventana, el Cardenal de Portinaris estaba dictando su testamento. A la primera clÃ¡usula que contenÃ­a su profesiÃ³n de Fe, habÃ­a logrado dar un giro distinto del acostumbrado, de manera que a la par de un compendio de la ReligiÃ³n CatÃ³lica resultaba un verdadero opÃºsculo literario. El Prelado, muy satisfecho, prosiguiÃ³ a enumerar cada uno de sus bienes, y al hacerlo, parecÃ­a que iban arrancÃ¡ndose las mÃ¡s hermosas pÃ¡ginas de la historia del arte. El notario escribÃ­a a toda prisa y, a pesar de estar muy acostumbrado a ese gÃ©nero de trabajos, se fatigaba en grado sumo, y gruesas gotas de sudor aparecÃ­an sobre su calva frente. -> 709\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: *       *       *       *       * -> [33, 33, 33]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --\"Estimado Padre Rodríguez: Le ruego se sirva dar cristiana sepultura al portador de la presente. Su afmo. Hermano en Xto. _Alonso Hurtado, S.J._\" -> [147]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Amigo mío, ese es mi secreto; pero puesto que a usted le debo mi fortuna, se lo diré, si me promete, si me jura, no decirlo mientras yo viva. En cuanto muera, queda usted en libertad para proclamarlo a los cuatro vientos. -> [223]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Amigo, dijo el Padre Hurtado, en esta casa no tenemos jardín. -> [63]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Angustias, ¿Qué hacen los muertos de la capilla, en la noche? -> [63]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Aquí tienes, dijo Antonio, a la persona que prometí presentarte. Como ves, es una obra de arte. Se llama Herrera Goya. Para que no te rías de un miembro de la familia, te contaré que Don Joaquín de Herrera Goya fué antepasado mío, aunque no en línea recta, pues murió soltero; su hermana, mi cuarta abuela, heredó de él esta hacienda y no sé si a ella se deba tan hermosa estatua. Es costumbre pintarla cada año; así como hoy la ves color de rosa, ha estado pintada de celeste, amarillo, verde, de todo menos de negro, pues hay aquí la creencia,--cosas de los indios,--que si llegara a pintarse de ese color, ocurriría alguna desgracia. La postura de sus manos indica, no que va a aplaudir, sino que la distancia que con ellos mide es el tamaño de los panes de azúcar que en su hacienda se fabricaban y que llenaron sus bolsillos de doblones. La tradición no cuenta cosas muy halagadoras para este señor; te las referiré algún día. -> [933]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Aun vivo, Eminencia, repuso el Conde sonriendo, e hizo ademÃ¡n de besar la mano del Prelado, pero Ã©ste la retirÃ³ disimuladamente indicando con ella una butaca cercana. TomÃ³ asiento el Conde, y despuÃ©s de unos instantes de embarazoso silencio, dijo: -> [254]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Buenas tardes, Padre, contestó Juan González, con el rostro iluminado por la esperanza. -> [89]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Buenas tardes. -> [16]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: --Buenos días, Padre. -> [21]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t*       *       *       *       *\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t*       *       *       *       *\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t*       *       *       *       *\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--\"Estimado Padre Rodríguez: Le ruego se sirva dar cristiana sepultura al portador de la presente. Su afmo. Hermano en Xto. _Alonso Hurtado, S.J._\"\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Amigo mío, ese es mi secreto; pero puesto que a usted le debo mi fortuna, se lo diré, si me promete, si me jura, no decirlo mientras yo viva. En cuanto muera, queda usted en libertad para proclamarlo a los cuatro vientos.\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Amigo, dijo el Padre Hurtado, en esta casa no tenemos jardín.\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Angustias, ¿Qué hacen los muertos de la capilla, en la noche?\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Aquí tienes, dijo Antonio, a la persona que prometí presentarte. Como ves, es una obra de arte. Se llama Herrera Goya. Para que no te rías de un miembro de la familia, te contaré que Don Joaquín de Herrera Goya fué antepasado mío, aunque no en línea recta, pues murió soltero; su hermana, mi cuarta abuela, heredó de él esta hacienda y no sé si a ella se deba tan hermosa estatua. Es costumbre pintarla cada año; así como hoy la ves color de rosa, ha estado pintada de celeste, amarillo, verde, de todo menos de negro, pues hay aquí la creencia,--cosas de los indios,--que si llegara a pintarse de ese color, ocurriría alguna desgracia. La postura de sus manos indica, no que va a aplaudir, sino que la distancia que con ellos mide es el tamaño de los panes de azúcar que en su hacienda se fabricaban y que llenaron sus bolsillos de doblones. La tradición no cuenta cosas muy halagadoras para este señor; te las referiré algún día.\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Aun vivo, Eminencia, repuso el Conde sonriendo, e hizo ademÃ¡n de besar la mano del Prelado, pero Ã©ste la retirÃ³ disimuladamente indicando con ella una butaca cercana. TomÃ³ asiento el Conde, y despuÃ©s de unos instantes de embarazoso silencio, dijo:\n",
      "\u001b[95mPárrafo > promedio\u001b[0m\t--Buenas tardes, Padre, contestó Juan González, con el rostro iluminado por la esperanza.\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, math\n",
    "sys.path.append(\"..\")\n",
    "from MRE import Job\n",
    "\n",
    "librosDir = \"./Libros/input\"\n",
    "out1Dir = \"./Libros/ej4_out1/\"\n",
    "\n",
    "# ===== Job 1: promedio de longitud de párrafos =====\n",
    "def fmap_len(key, value, context):\n",
    "    length = len(value.strip())\n",
    "    context.write(1, length)\n",
    "\n",
    "def fred_len(key, values, context):\n",
    "    total, n = 0, 0\n",
    "    for v in values:\n",
    "        total += v\n",
    "        n += 1\n",
    "    avg = total / n if n > 0 else 0\n",
    "    context.write(\"promedio\", avg)\n",
    "\n",
    "job1 = Job(librosDir, out1Dir, fmap_len, fred_len)\n",
    "job1.waitForCompletion()\n",
    "\n",
    "out2Dir = \"./Libros/ej4_out2/\"\n",
    "\n",
    "# ===== Job 2: filtrar párrafos mayores al promedio =====\n",
    "def fmap_filter(key, value, context):\n",
    "    length = len(value.strip())\n",
    "    context.write(value.strip(), length)\n",
    "\n",
    "def fred_filter(parrafo, values, context):\n",
    "    avg = context[\"avg\"]\n",
    "    for v in values:\n",
    "        if v > avg:\n",
    "            context.write(\"Párrafo > promedio\", parrafo)\n",
    "\n",
    "params = {\"avg\": promedio}\n",
    "job2 = Job(librosDir, out2Dir, fmap_filter, fred_filter)\n",
    "job2.setParams(params)\n",
    "job2.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec15c4b-9c10-4632-a7a2-fd92672b0ec2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 5\n",
    "\n",
    "El dataset website tiene información sobre el tiempo de permanencia de sus usuarios\n",
    "en cada una de las páginas del sitio. El formato de los datos del dataset es:\n",
    "<id_user, id_page, time>\n",
    "Implemente una aplicación MapReduce, utilizando combiners en los casos que\n",
    "considere necesario, que calcule\n",
    "\n",
    "> Indique como queda el DAG del proceso completo (las tres consultas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723344e-ca9b-45bb-9ace-f13c21f96808",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### a. La página más visitada (la página en la que más tiempo permaneció) para cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cecff47-6285-4ecd-948b-4ff5c26a878b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m ('9482', '1590') -> 37\n",
      "\u001b[94m[Map]\u001b[0m ('13156', '1084') -> 65\n",
      "\u001b[94m[Map]\u001b[0m ('9601', '3819') -> 75\n",
      "\u001b[94m[Map]\u001b[0m ('11171', '2899') -> 42\n",
      "\u001b[94m[Map]\u001b[0m ('11744', '1272') -> 79\n",
      "\u001b[94m[Map]\u001b[0m ('9619', '3160') -> 62\n",
      "\u001b[94m[Map]\u001b[0m ('12961', '3803') -> 66\n",
      "\u001b[94m[Map]\u001b[0m ('8832', '2613') -> 36\n",
      "\u001b[94m[Map]\u001b[0m ('11404', '1016') -> 11\n",
      "\u001b[94m[Map]\u001b[0m ('11092', '3363') -> 11\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10000', '2332') -> [81]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10000', '2852') -> [52]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10001', '2903') -> [82]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10002', '1353') -> [27]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10002', '2699') -> [24]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10004', '3676') -> [30]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10005', '3079') -> [21]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10007', '1084') -> [6]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10007', '3095') -> [65]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: ('10008', '1986') -> [6]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m('10000', '2332')\u001b[0m\t81\n",
      "\u001b[95m('10000', '2852')\u001b[0m\t52\n",
      "\u001b[95m('10001', '2903')\u001b[0m\t82\n",
      "\u001b[95m('10002', '1353')\u001b[0m\t27\n",
      "\u001b[95m('10002', '2699')\u001b[0m\t24\n",
      "\u001b[95m('10004', '3676')\u001b[0m\t30\n",
      "\u001b[95m('10005', '3079')\u001b[0m\t21\n",
      "\u001b[95m('10007', '1084')\u001b[0m\t6\n",
      "\u001b[95m('10007', '3095')\u001b[0m\t65\n",
      "\u001b[95m('10008', '1986')\u001b[0m\t6\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 10000 -> ('2332', 81)\n",
      "\u001b[94m[Map]\u001b[0m 10008 -> ('2693', 34)\n",
      "\u001b[94m[Map]\u001b[0m 10024 -> ('2491', 95)\n",
      "\u001b[94m[Map]\u001b[0m 10032 -> ('3077', 13)\n",
      "\u001b[94m[Map]\u001b[0m 10045 -> ('2016', 19)\n",
      "\u001b[94m[Map]\u001b[0m 10060 -> ('2797', 3)\n",
      "\u001b[94m[Map]\u001b[0m 10070 -> ('1194', 3)\n",
      "\u001b[94m[Map]\u001b[0m 10080 -> ('1724', 92)\n",
      "\u001b[94m[Map]\u001b[0m 10092 -> ('3902', 46)\n",
      "\u001b[94m[Map]\u001b[0m 10105 -> ('1291', 32)\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10000 -> [('2332', 81), ('2852', 52)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10001 -> [('2903', 82)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10002 -> [('1353', 27), ('2699', 24)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10004 -> [('3676', 30)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10005 -> [('3079', 21)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10007 -> [('1084', 6), ('3095', 65)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10008 -> [('2693', 34), ('1986', 6)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10009 -> [('1586', 48), ('3638', 9), ('3926', 63)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10011 -> [('2720', 71)]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10012 -> [('3152', 67)]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m10000\u001b[0m\t2332\n",
      "\u001b[95m10001\u001b[0m\t2903\n",
      "\u001b[95m10002\u001b[0m\t1353\n",
      "\u001b[95m10004\u001b[0m\t3676\n",
      "\u001b[95m10005\u001b[0m\t3079\n",
      "\u001b[95m10007\u001b[0m\t3095\n",
      "\u001b[95m10008\u001b[0m\t2693\n",
      "\u001b[95m10009\u001b[0m\t3926\n",
      "\u001b[95m10011\u001b[0m\t2720\n",
      "\u001b[95m10012\u001b[0m\t3152\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from MRE import Job\n",
    "\n",
    "# directorios de trabajo\n",
    "inputDir = \"./website/input/\"\n",
    "out1 = \"./website/out_A1/\"\n",
    "out2 = \"./website/out_A2/\"\n",
    "\n",
    "# agrupa por (user, page)\n",
    "def fmap_1(user_id, value, context):\n",
    "    parts = value.strip().split('\\t')\n",
    "    page_id, time = parts\n",
    "    context.write((user_id, page_id), int(time))\n",
    "\n",
    "# reduce: suma tiempos por (user, page)\n",
    "def fred_1(key, values, context):\n",
    "    total_time = 0\n",
    "    for t in values:\n",
    "        total_time += t\n",
    "    context.write(key, total_time)\n",
    "\n",
    "# agrupa por user\n",
    "def fmap_2(user_id, value, context):\n",
    "    parts = value.strip().split('\\t')\n",
    "    page_id, total_time = parts\n",
    "    context.write(user_id, (page_id, int(total_time)))\n",
    "\n",
    "# reduce: selecciona la página con más tiempo\n",
    "def fred_2(user_id, values, context):\n",
    "    max_time = -1\n",
    "    best_page = None\n",
    "    for page_id, t in values:\n",
    "        if t > max_time:\n",
    "            max_time = t\n",
    "            best_page = page_id\n",
    "    context.write(user_id, best_page)\n",
    "\n",
    "job1 = Job(inputDir, out1, fmap_1, fred_1)\n",
    "job1.setCombiner(fred_1)\n",
    "job1.waitForCompletion()\n",
    "\n",
    "job2 = Job(out1, out2, fmap_2, fred_2)\n",
    "job2.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c7a132-a434-4ebe-a719-6483a1b82680",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### b. El usuario que más páginas distintas visitó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92136928-4243-49eb-a423-4073181ff086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 10000 -> 2332\n",
      "\u001b[94m[Map]\u001b[0m 10008 -> 2693\n",
      "\u001b[94m[Map]\u001b[0m 10024 -> 2491\n",
      "\u001b[94m[Map]\u001b[0m 10032 -> 3077\n",
      "\u001b[94m[Map]\u001b[0m 10045 -> 2016\n",
      "\u001b[94m[Map]\u001b[0m 10060 -> 2797\n",
      "\u001b[94m[Map]\u001b[0m 10070 -> 1194\n",
      "\u001b[94m[Map]\u001b[0m 10080 -> 1724\n",
      "\u001b[94m[Map]\u001b[0m 10092 -> 3902\n",
      "\u001b[94m[Map]\u001b[0m 10105 -> 1291\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10000 -> ['2332', '2852']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10001 -> ['2903']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10002 -> ['1353', '2699']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10004 -> ['3676']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10005 -> ['3079']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10007 -> ['1084', '3095']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10008 -> ['2693', '1986']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10009 -> ['1586', '3638', '3926']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10011 -> ['2720']\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 10012 -> ['3152']\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m10000\u001b[0m\t2\n",
      "\u001b[95m10001\u001b[0m\t1\n",
      "\u001b[95m10002\u001b[0m\t2\n",
      "\u001b[95m10004\u001b[0m\t1\n",
      "\u001b[95m10005\u001b[0m\t1\n",
      "\u001b[95m10007\u001b[0m\t2\n",
      "\u001b[95m10008\u001b[0m\t2\n",
      "\u001b[95m10009\u001b[0m\t3\n",
      "\u001b[95m10011\u001b[0m\t1\n",
      "\u001b[95m10012\u001b[0m\t1\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10000', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10013', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10036', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10054', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10070', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10090', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10110', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10125', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10143', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('10167', 1)\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1 -> [('10000', 2), ('10013', 1), ('10036', 2), ('10054', 3), ('10070', 2), ('10090', 1), ('10110', 1), ('10125', 1), ('10143', 1), ('10167', 1), '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mUsuario con más páginas distintas\u001b[0m\t('9458', 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directorios de salida para inciso B\n",
    "out3 = \"./website/out_B1/\"\n",
    "out4 = \"./website/out_B2/\"\n",
    "\n",
    "# cuenta páginas distintas por usuario\n",
    "def fmap_3(user_id, value, context):\n",
    "    parts = value.strip().split('\\t')\n",
    "    page_id, _ = parts\n",
    "    context.write(user_id, page_id)\n",
    "\n",
    "def fred_3(user_id, values, context):\n",
    "    distinct_pages = set(values)\n",
    "    context.write(user_id, len(distinct_pages))\n",
    "\n",
    "# agrupa todos los (user, count) bajo una misma clave\n",
    "def fmap_4(user_id, value, context):\n",
    "    context.write(1, (user_id, int(value.strip())))\n",
    "\n",
    "def fred_max(_, values, context):\n",
    "    best_user, max_count = None, -1\n",
    "    for user, c in values:\n",
    "        if c > max_count:\n",
    "            max_count = c\n",
    "            best_user = user\n",
    "    context.write(\"Usuario con más páginas distintas\", (best_user, max_count))\n",
    "\n",
    "job3 = Job(out1, out3, fmap_3, fred_3)\n",
    "job3.waitForCompletion()\n",
    "\n",
    "job4 = Job(out3, out4, fmap_4, fred_max)\n",
    "job4.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c7dc4-a7dd-414f-b647-4eb6000d7b54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### c. La página más visitada (en cuanto a cantidad de visitas, sin importar el tiempo de permanencia) por todos los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f8ffa30-b569-4cc8-a746-683c5056a84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 3876 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3492 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1966 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 2419 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1793 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 2930 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3415 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 2351 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 3120 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1675 -> 1\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1000 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1001 -> [1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1002 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1003 -> [1, 1, 1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1005 -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1006 -> [1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1007 -> [1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1008 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1010 -> [1, 1, 1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1011 -> [1, 1]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m1000\u001b[0m\t1\n",
      "\u001b[95m1001\u001b[0m\t3\n",
      "\u001b[95m1002\u001b[0m\t1\n",
      "\u001b[95m1003\u001b[0m\t5\n",
      "\u001b[95m1005\u001b[0m\t2\n",
      "\u001b[95m1006\u001b[0m\t2\n",
      "\u001b[95m1007\u001b[0m\t3\n",
      "\u001b[95m1008\u001b[0m\t1\n",
      "\u001b[95m1010\u001b[0m\t3\n",
      "\u001b[95m1011\u001b[0m\t2\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1000 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1012 -> 3\n",
      "\u001b[94m[Map]\u001b[0m 1025 -> 2\n",
      "\u001b[94m[Map]\u001b[0m 1036 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1047 -> 3\n",
      "\u001b[94m[Map]\u001b[0m 1058 -> 2\n",
      "\u001b[94m[Map]\u001b[0m 1073 -> 2\n",
      "\u001b[94m[Map]\u001b[0m 1085 -> 1\n",
      "\u001b[94m[Map]\u001b[0m 1096 -> 3\n",
      "\u001b[94m[Map]\u001b[0m 1107 -> 2\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1000 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1001 -> [3]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1002 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1003 -> [5]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1005 -> [2]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1006 -> [2]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1007 -> [3]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1008 -> [1]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1010 -> [3]\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1011 -> [2]\n",
      "\u001b[96m... [más reduce claves omitidas]\u001b[0m\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95m1000\u001b[0m\t1\n",
      "\u001b[95m1001\u001b[0m\t3\n",
      "\u001b[95m1002\u001b[0m\t1\n",
      "\u001b[95m1003\u001b[0m\t5\n",
      "\u001b[95m1005\u001b[0m\t2\n",
      "\u001b[95m1006\u001b[0m\t2\n",
      "\u001b[95m1007\u001b[0m\t3\n",
      "\u001b[95m1008\u001b[0m\t1\n",
      "\u001b[95m1010\u001b[0m\t3\n",
      "\u001b[95m1011\u001b[0m\t2\n",
      "\u001b[91m... [más resultados omitidos]\u001b[0m\n",
      "\u001b[94m[MRE] INICIANDO ETAPA DE MAPEO...\u001b[0m\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1000', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1012', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1025', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1036', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1047', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1058', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1073', 2)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1085', 1)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1096', 3)\n",
      "\u001b[94m[Map]\u001b[0m 1 -> ('1107', 2)\n",
      "\u001b[94m... [más resultados de map omitidos]\u001b[0m\n",
      "\u001b[96m[MRE] INICIANDO ETAPA DE REDUCCIÓN...\u001b[0m\n",
      "\u001b[96m[Reduce]\u001b[0m Clave recibida: 1 -> [('1000', 1), ('1012', 3), ('1025', 2), ('1036', 1), ('1047', 3), ('1058', 2), ('1073', 2), ('1085', 1), ('1096', 3), ('1107', 2), '...']\n",
      "\u001b[93m[MRE] FINALIZANDO Y ESCRIBIENDO RESULTADOS EN DISCO...\u001b[0m\n",
      "\u001b[92m\n",
      "[MRE] RESULTADOS FINALES DEL JOB:\u001b[0m\n",
      "\u001b[95mPágina más visitada\u001b[0m\t('1694', 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directorios de salida para inciso C\n",
    "out5 = \"./website/out_C1/\"\n",
    "out6 = \"./website/out_C2/\"\n",
    "out7 = \"./website/out_C3/\"\n",
    "\n",
    "# ---------------- JOB 5 ----------------\n",
    "# Emite (page_id, 1) por cada visita\n",
    "def fmap_5(user_id, value, context):\n",
    "    parts = value.strip().split('\\t') \n",
    "    page_id, time = parts   # el tiempo no importa acá\n",
    "    context.write(page_id, 1)\n",
    "\n",
    "def fred_count(page_id, values, context):\n",
    "    total_visits = sum(values)\n",
    "    context.write(page_id, total_visits)\n",
    "\n",
    "# ---------------- JOB 6 ----------------\n",
    "# Junta todas las visitas de cada página (ya están como enteros)\n",
    "def fmap_6(page_id, value, context):\n",
    "    context.write(page_id, int(value.strip()))\n",
    "\n",
    "def fred_sum(page_id, values, context):\n",
    "    total = sum(values)\n",
    "    context.write(page_id, total)\n",
    "\n",
    "# ---------------- JOB 7 ----------------\n",
    "# Busca la página con más visitas\n",
    "def fmap_7(page_id, value, context):\n",
    "    context.write(1, (page_id, int(value.strip())))\n",
    "\n",
    "def fred_max(_, values, context):\n",
    "    max_count = -1\n",
    "    best_page = None\n",
    "    for page, count in values:\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            best_page = page\n",
    "    context.write(\"Página más visitada\", (best_page, max_count))\n",
    "\n",
    "job5 = Job(inputDir, out5, fmap_5, fred_count)\n",
    "job5.waitForCompletion()\n",
    "\n",
    "job6 = Job(out5, out6, fmap_6, fred_sum)\n",
    "job6.waitForCompletion()\n",
    "\n",
    "job7 = Job(out6, out7, fmap_7, fred_max)\n",
    "job7.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0d5ca-3366-409a-a318-f5c209773fca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6) Cómo plantearía una solución MapReduce a los siguientes algoritmos secuenciales:\n",
    "\n",
    "i. entrada\n",
    "\n",
    "```\n",
    "textos: array [1..N] of string (dataset libros)\n",
    "```\n",
    "ii. algoritmo\n",
    "\n",
    "```python\n",
    "a={}; b={}; N = len(textos)\n",
    "for l in textos:\n",
    "    words = l.split()\n",
    "    for w in words:\n",
    "        a[w] = a[w]+1\n",
    "\n",
    "for w in a.keys():\n",
    "    for l in lines:\n",
    "        words = l.split()\n",
    "        if w in words:\n",
    "            b[w]=b[w]+1\n",
    "for k in a.keys():\n",
    "    print(k + \" = \" + str(a[w] * (N / b[w])))\n",
    "```\n",
    "\n",
    "El algoritmo secuencial trabaja como una variante de **TF-IDF** (frecuencia de palabra por documento).\n",
    "Hace tres cosas:\n",
    "\n",
    "1. Cuenta cuántas veces aparece cada palabra en todo el dataset (`a[w]`).\n",
    "2. Cuenta en cuántos documentos (líneas o párrafos) aparece cada palabra (`b[w]`).\n",
    "3. Devuelve para cada palabra: `a[w] * (N / b[w])`, donde `N` es la cantidad total de documentos.\n",
    "\n",
    "**Cómo se plantea en MapReduce**\n",
    "\n",
    "Este problema no se resuelve con un solo job, sino con **tres jobs encadenados**:\n",
    "\n",
    "* **Job 1 (contar ocurrencias totales de palabras):**\n",
    "\n",
    "  * *Map:* cada mapper toma un documento y por cada palabra emite `(palabra, 1)`.\n",
    "  * *Reduce:* los reducers suman esos 1 y obtienen cuántas veces aparece cada palabra en todo el dataset.\n",
    "  * **Salida:** `(palabra, total_ocurrencias)` → esto es `a[w]`.\n",
    "\n",
    "* **Job 2 (contar en cuántos documentos aparece cada palabra):**\n",
    "\n",
    "  * *Map:* cada mapper toma un documento y por cada palabra distinta en ese documento emite `(palabra, doc_id)`.\n",
    "  * *Reduce:* para cada palabra, cuenta la cantidad de `doc_id` distintos → en cuántos documentos aparece.\n",
    "  * **Salida:** `(palabra, num_docs)` → esto es `b[w]`.\n",
    "\n",
    "* **Job 3 (cálculo final):**\n",
    "\n",
    "  * *Map:* se unen las salidas de Job1 y Job2 por clave (la palabra).\n",
    "  * *Reduce:* con `a[w]` y `b[w]` calcula `a[w] * (N / b[w])`.\n",
    "  * **Salida final:** `(palabra, score)`.\n",
    "\n",
    "🔗 El **DAG** se ve así:\n",
    "\n",
    "```\n",
    "Dataset Libros\n",
    " ├─ Job1 → a[w] = total ocurrencias\n",
    " ├─ Job2 → b[w] = nº de documentos con w\n",
    " └─ Job3 (join y cálculo) → resultado final\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "b.\n",
    "i. entrada\n",
    "```\n",
    "datos: array [1..N] of /<int1, int2, ..., intM> (todos los valores están dentro de un rango de valores conocido, para poder usarlos como índices del tensor)\n",
    "```\n",
    "ii. algoritmo\n",
    "\n",
    "```python\n",
    "for t in datos:\n",
    "    v = t.split(\"\\t\")\n",
    "    c = v[-1]\n",
    "        for a in range(len(v)-1):\n",
    "        x= v[a]\n",
    "        m[a][x][c] = m[a][x][c] + 1\n",
    "\n",
    "max=[[0,0,0], [0,0,0]]\n",
    "for x in range(len(m)):\n",
    "    for y in range(len(m[0])):\n",
    "        for z in range(2):\n",
    "            if(m[x][y][z] > max[z][0]):\n",
    "                max[z][0] = m[x][y][z]\n",
    "                max[z][1]=x\n",
    "                max[z][2]=y\n",
    "\n",
    "for z in range(2):\n",
    "    print(z +\";\" + max[z][1] +\";\" + max[z][2])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "El algoritmo secuencial toma un dataset de tuplas `<x1, x2, …, xM, c>` (atributos + clase).\n",
    "Hace dos cosas:\n",
    "\n",
    "1. Construye una especie de “tensor de frecuencias” `m[a][x][c]`, que cuenta cuántas veces el atributo `a` tomó el valor `x` en ejemplos de clase `c`.\n",
    "2. Busca, para cada clase `c`, cuál es el valor de atributo que más se repite.\n",
    "\n",
    "**Cómo se plantea en MapReduce**\n",
    "\n",
    "Este problema se resuelve en **dos jobs**:\n",
    "\n",
    "* **Job 1 (conteo de triples atributo–valor–clase):**\n",
    "\n",
    "  * *Map:* para cada tupla `<x1, …, xM, c>`, emite `(a, x, c) → 1` para cada atributo `a` y su valor `x`.\n",
    "  * *Reduce:* para cada triple `(a, x, c)` suma todas las ocurrencias.\n",
    "  * **Salida:** `(a, x, c, count)` → cuántas veces apareció el valor `x` del atributo `a` en la clase `c`.\n",
    "\n",
    "* **Job 2 (buscar máximos por clase):**\n",
    "\n",
    "  * *Map:* reemite los resultados del Job 1 pero agrupando por clase `c`.\n",
    "  * *Reduce:* para cada clase `c`, recorre todos los `(a, x, count)` y selecciona el de mayor frecuencia.\n",
    "  * **Salida final:** `(c, mejor atributo=a, valor=x, count)`.\n",
    "\n",
    "🔗 El **DAG** se ve así:\n",
    "\n",
    "```\n",
    "Dataset Datos\n",
    " ├─ Job1 → conteo de (atributo, valor, clase)\n",
    " └─ Job2 → selección del máximo por clase\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f6aa4-cfd5-4146-b041-28fdc562dfac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
