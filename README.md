# Big Data

---

- [游늿 Practica 1](practica_1.ipynb)
- [游 Notas Clase 2](#notas-clase-2)
- [游늿 Practica 2](practica_2.ipynb)
- [游 Notas Clase 3](#notas-clase-3)
- [游늿 Practica 3](practica_3.ipynb)
- [游 Notas Clase 4](#notas-clase-4)
- [游늿 Practica 4](practica_4.ipynb)

---

Creamos el entorno
```
python -m venv venv
```

Activamos el entorno

```
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass; .\venv\Scripts\Activate
```

```
pip install --upgrade pip
pip install jupyterlab
```

```
jupyter lab
```

---

## Notas Clase 2

### Repaso del Paradigma MapReduce

- MapReduce organiza el procesamiento en **jobs** como unidad m칤nima de trabajo
- Cada job se divide en fases **map** y **reduce**
- Los datos llegan en formato de tuplas clave-valor
- Cada mapper procesa solo una porci칩n de los datos sin conocer el contexto global
- Los reducers reciben claves generadas por los mappers y todos los valores asociados a cada clave
- El iterador de valores en la fase reduce solo puede recorrerse una vez y no se puede indexar

### La Funci칩n Combiner para Optimizaci칩n

- El principal problema de MapReduce es el volumen de datos intermedios transferidos entre nodos
- La funci칩n Combiner es una optimizaci칩n que minimiza la cantidad de datos transferidos
- Se ejecuta en el mismo nodo donde se ejecut칩 el mapper, trabajando con datos en memoria RAM
- Se invoca cuando el buffer de memoria se llena, antes de escribir a disco
- No hay garant칤a de cu치ntas veces se ejecutar치 (es una optimizaci칩n opcional)
- La entrada y salida deben tener la misma estructura (K2V2)
- En la mayor칤a de casos, la funci칩n Combiner es id칠ntica a la funci칩n Reduce

### Beneficios del Combiner

- Reduce significativamente el volumen de datos intermedios
- Optimiza el uso de memoria RAM
- Minimiza la transferencia de datos a trav칠s de la red del cluster
- Ejemplo: En WordCount, si una palabra aparece 100 veces en un split, el Combiner reduce estos 100 pares a un solo par (palabra, 100)

### Problemas Complejos

- Algunos problemas requieren c치lculos que no pueden resolverse en un solo job
- Ejemplo: Calcular el desv칤o est치ndar de compras en un hipermercado
    - Requiere conocer el promedio primero
    - Como el iterador de valores solo puede recorrerse una vez, necesitamos dos jobs:
        1. Primer job para calcular el promedio
        2. Segundo job para calcular el desv칤o est치ndar usando el promedio

### Pr칩ximo Tema

- En el segundo video se abordar치 c칩mo resolver problemas que requieren la ejecuci칩n de m치s de un job
- Tambi칠n se tratar치n casos donde es 칰til enviar informaci칩n extra a los mappers y reducers

---

## Notas Clase 3

### Conceptos Fundamentales

- Los problemas m치s complejos requieren ejecutar m치s de un job MapReduce
- Los jobs se ejecutan secuencialmente (un job completo termina antes de iniciar el siguiente)
- DAG (Grafo Ac칤clico Dirigido) permite visualizar el flujo de procesamiento
- La salida de un job puede servir como entrada para otro job
- Es posible parametrizar funciones Map y Reduce para enviarles informaci칩n adicional

### Problema del Desv칤o Est치ndar

- Requiere calcular primero el promedio (Job 1) y luego usarlo para calcular el desv칤o (Job 2)
- El dataset completo se utiliza dos veces en jobs diferentes
- El promedio calculado en el primer job debe pasarse como par치metro al segundo job

### An치lisis de Logs Web

- Dataset: ID de usuario, ID de p치gina, tiempo de permanencia
- Objetivo: encontrar para cada usuario la p치gina donde pas칩 m치s tiempo
- Soluci칩n en dos jobs:
    - Job 1: Usa (idUsuario, idP치gina) como clave intermedia para acumular tiempos
    - Job 2: Usa idUsuario como clave para encontrar la p치gina con mayor tiempo acumulado

### Algoritmos Iterativos

- Necesitan recorrer el dataset completo varias veces
- Ejemplos: clustering, TF-IDF, PageRank, entrenamiento de redes neuronales
- M칠todo de Jacobi como ejemplo:
    - Resuelve sistemas de ecuaciones lineales iterativamente
    - Cada iteraci칩n usa valores de la anterior
    - Termina cuando la diferencia entre iteraciones es menor que un umbral

### Parametrizaci칩n de Funciones

- Permite pasar informaci칩n adicional a Map y Reduce
- Se configura desde el driver usando setParams()
- 칔til para:
    - Pasar resultados entre jobs (como el promedio al job de desv칤o est치ndar)
    - Pasar valores de iteraciones anteriores (como en Jacobi)
    - Compartir configuraciones o datos calculados previamente

### Implementaci칩n de Algoritmos Iterativos

- Requiere un bucle (while) en el driver que controle las iteraciones
- Cada iteraci칩n ejecuta un job completo
- Los resultados de cada job se usan para:

---

## Notas Clase 4

### Concepto General

El paradigma MapReduce permite implementar operaciones similares a SQL (filtros, res칰menes, transformaciones y JOIN) en entornos de Big Data. En esta clase se utiliza el ejemplo de una base de datos bancaria con tres tablas (Cliente, Caja de Ahorro y Pr칠stamo) almacenadas como archivos en directorios diferentes del HDFS.

### Operaciones B치sicas

- **GROUP BY (Agrupaci칩n)**: Similar a WordCount, donde la clave del Map es el campo de agrupaci칩n y el Reduce implementa la funci칩n de agregaci칩n.
- **Filtros (WHERE)**: Se implementan en la fase Map para minimizar datos transferidos entre mappers y reducers.
- **Proyecciones (SELECT)**: El Map emite solo los campos necesarios, funcionando como un filtro por columnas.
- **DISTINCT**: Se implementa haciendo que el Reduce escriba solo una tupla para cada clave, ignorando duplicados.

### Operaci칩n JOIN

- **Desaf칤o principal**: Las tablas est치n en directorios diferentes del HDFS.
- **Implementaci칩n**:
    - Opci칩n 1: Una 칰nica funci칩n Map que procesa datos de ambas tablas
    - Opci칩n 2: Dos funciones Map diferentes, una para cada tabla
- **JOIN 1:1 (Caja de Ahorro-Pr칠stamo)**:
    - Map emite el ID de caja como clave para ambas tablas
    - Reduce recibe registros de ambas tablas con la misma clave
    - Se necesita identificar a qu칠 tabla pertenece cada registro (usar etiquetas)
- **JOIN 1:N (Cliente-Caja de Ahorro)**:
    - M치s complejo porque un cliente puede tener m칰ltiples cajas de ahorro
    - Es necesario procesar primero los datos del cliente en el Reduce

### Control de Orden en MapReduce

- **Fases Shuffle y Sort**: Etapas intermedias entre Map y Reduce
    - **Shuffle**: Agrupa registros con la misma clave para el mismo Reducer
    - **Sort**: Ordena las claves antes de enviarlas al Reducer
- **Comparadores personalizados**:
    - Comparador Shuffle: Define qu칠 claves son "iguales" para agrupar
    - Comparador Sort: Define el orden en que las claves llegan al Reducer
    - Permiten controlar el orden de procesamiento en joins complejos

### Optimizaci칩n de Consultas Complejas

- Estrategia de optimizaci칩n:
    1. Descomponer la consulta en operaciones simples (filtros, joins, agrupaciones)
    2. Crear un grafo dirigido ac칤clico (DAG) de operaciones
    3. Optimizar combinando m칰ltiples operaciones en menos jobs
    4. Minimizar lecturas/escrituras de datos entre jobs

### Conclusi칩n

La implementaci칩n de operaciones complejas en MapReduce requiere pensar en t칠rminos de Map y Reduce, personalizar el comportamiento de Shuffle y Sort, y optimizar el flujo de datos para minimizar operaciones de E/S. La pr칩xima clase abordar치 el framework Spark.

### Reflexi칩n Final

- [ ]  Considerar si es posible implementar toda la consulta compleja presentada al final en un 칰nico job MapReduce