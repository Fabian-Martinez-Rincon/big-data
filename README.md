<div align="center">

# üóÇÔ∏è Big Data

<img src='https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExNGg2bnJxMG1oeXM2d2NyczkzcWZ3eXp4cHlnbzUwOGUwZTVhcnBhOSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/aMwdfGSyeYjUKY6vjf/giphy.gif'>

</div>

---

- [üìï Practica 1](practica_1.ipynb)
- [üìí Notas Clase 2](#notas-clase-2)
- [üìï Practica 2](practica_2.ipynb)
- [üìí Notas Clase 3](#notas-clase-3)
- [üìï Practica 3](practica_3.ipynb)
- [üìí Notas Clase 4](#notas-clase-4)
- [üìï Practica 4](practica_4.ipynb)

---

Creamos el entorno
```
python -m venv venv
```

Activamos el entorno

```
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass; .\venv\Scripts\Activate
```

```
pip install --upgrade pip
pip install jupyterlab
```

```
jupyter lab
```

---

## Notas Clase 2

### Repaso del Paradigma MapReduce

- MapReduce organiza el procesamiento en **jobs** como unidad m√≠nima de trabajo
- Cada job se divide en fases **map** y **reduce**
- Los datos llegan en formato de tuplas clave-valor
- Cada mapper procesa solo una porci√≥n de los datos sin conocer el contexto global
- Los reducers reciben claves generadas por los mappers y todos los valores asociados a cada clave
- El iterador de valores en la fase reduce solo puede recorrerse una vez y no se puede indexar

### La Funci√≥n Combiner para Optimizaci√≥n

- El principal problema de MapReduce es el volumen de datos intermedios transferidos entre nodos
- La funci√≥n Combiner es una optimizaci√≥n que minimiza la cantidad de datos transferidos
- Se ejecuta en el mismo nodo donde se ejecut√≥ el mapper, trabajando con datos en memoria RAM
- Se invoca cuando el buffer de memoria se llena, antes de escribir a disco
- No hay garant√≠a de cu√°ntas veces se ejecutar√° (es una optimizaci√≥n opcional)
- La entrada y salida deben tener la misma estructura (K2V2)
- En la mayor√≠a de casos, la funci√≥n Combiner es id√©ntica a la funci√≥n Reduce

### Beneficios del Combiner

- Reduce significativamente el volumen de datos intermedios
- Optimiza el uso de memoria RAM
- Minimiza la transferencia de datos a trav√©s de la red del cluster
- Ejemplo: En WordCount, si una palabra aparece 100 veces en un split, el Combiner reduce estos 100 pares a un solo par (palabra, 100)

### Problemas Complejos

- Algunos problemas requieren c√°lculos que no pueden resolverse en un solo job
- Ejemplo: Calcular el desv√≠o est√°ndar de compras en un hipermercado
    - Requiere conocer el promedio primero
    - Como el iterador de valores solo puede recorrerse una vez, necesitamos dos jobs:
        1. Primer job para calcular el promedio
        2. Segundo job para calcular el desv√≠o est√°ndar usando el promedio

### Pr√≥ximo Tema

- En el segundo video se abordar√° c√≥mo resolver problemas que requieren la ejecuci√≥n de m√°s de un job
- Tambi√©n se tratar√°n casos donde es √∫til enviar informaci√≥n extra a los mappers y reducers

---

## Notas Clase 3

### Conceptos Fundamentales

- Los problemas m√°s complejos requieren ejecutar m√°s de un job MapReduce
- Los jobs se ejecutan secuencialmente (un job completo termina antes de iniciar el siguiente)
- DAG (Grafo Ac√≠clico Dirigido) permite visualizar el flujo de procesamiento
- La salida de un job puede servir como entrada para otro job
- Es posible parametrizar funciones Map y Reduce para enviarles informaci√≥n adicional

### Problema del Desv√≠o Est√°ndar

- Requiere calcular primero el promedio (Job 1) y luego usarlo para calcular el desv√≠o (Job 2)
- El dataset completo se utiliza dos veces en jobs diferentes
- El promedio calculado en el primer job debe pasarse como par√°metro al segundo job

### An√°lisis de Logs Web

- Dataset: ID de usuario, ID de p√°gina, tiempo de permanencia
- Objetivo: encontrar para cada usuario la p√°gina donde pas√≥ m√°s tiempo
- Soluci√≥n en dos jobs:
    - Job 1: Usa (idUsuario, idP√°gina) como clave intermedia para acumular tiempos
    - Job 2: Usa idUsuario como clave para encontrar la p√°gina con mayor tiempo acumulado

### Algoritmos Iterativos

- Necesitan recorrer el dataset completo varias veces
- Ejemplos: clustering, TF-IDF, PageRank, entrenamiento de redes neuronales
- M√©todo de Jacobi como ejemplo:
    - Resuelve sistemas de ecuaciones lineales iterativamente
    - Cada iteraci√≥n usa valores de la anterior
    - Termina cuando la diferencia entre iteraciones es menor que un umbral

### Parametrizaci√≥n de Funciones

- Permite pasar informaci√≥n adicional a Map y Reduce
- Se configura desde el driver usando setParams()
- √ötil para:
    - Pasar resultados entre jobs (como el promedio al job de desv√≠o est√°ndar)
    - Pasar valores de iteraciones anteriores (como en Jacobi)
    - Compartir configuraciones o datos calculados previamente

### Implementaci√≥n de Algoritmos Iterativos

- Requiere un bucle (while) en el driver que controle las iteraciones
- Cada iteraci√≥n ejecuta un job completo
- Los resultados de cada job se usan para:

---

## Notas Clase 4

### Concepto General

El paradigma MapReduce permite implementar operaciones similares a SQL (filtros, res√∫menes, transformaciones y JOIN) en entornos de Big Data. En esta clase se utiliza el ejemplo de una base de datos bancaria con tres tablas (Cliente, Caja de Ahorro y Pr√©stamo) almacenadas como archivos en directorios diferentes del HDFS.

### Operaciones B√°sicas

- **GROUP BY (Agrupaci√≥n)**: Similar a WordCount, donde la clave del Map es el campo de agrupaci√≥n y el Reduce implementa la funci√≥n de agregaci√≥n.
- **Filtros (WHERE)**: Se implementan en la fase Map para minimizar datos transferidos entre mappers y reducers.
- **Proyecciones (SELECT)**: El Map emite solo los campos necesarios, funcionando como un filtro por columnas.
- **DISTINCT**: Se implementa haciendo que el Reduce escriba solo una tupla para cada clave, ignorando duplicados.

### Operaci√≥n JOIN

- **Desaf√≠o principal**: Las tablas est√°n en directorios diferentes del HDFS.
- **Implementaci√≥n**:
    - Opci√≥n 1: Una √∫nica funci√≥n Map que procesa datos de ambas tablas
    - Opci√≥n 2: Dos funciones Map diferentes, una para cada tabla
- **JOIN 1:1 (Caja de Ahorro-Pr√©stamo)**:
    - Map emite el ID de caja como clave para ambas tablas
    - Reduce recibe registros de ambas tablas con la misma clave
    - Se necesita identificar a qu√© tabla pertenece cada registro (usar etiquetas)
- **JOIN 1:N (Cliente-Caja de Ahorro)**:
    - M√°s complejo porque un cliente puede tener m√∫ltiples cajas de ahorro
    - Es necesario procesar primero los datos del cliente en el Reduce

### Control de Orden en MapReduce

- **Fases Shuffle y Sort**: Etapas intermedias entre Map y Reduce
    - **Shuffle**: Agrupa registros con la misma clave para el mismo Reducer
    - **Sort**: Ordena las claves antes de enviarlas al Reducer
- **Comparadores personalizados**:
    - Comparador Shuffle: Define qu√© claves son "iguales" para agrupar
    - Comparador Sort: Define el orden en que las claves llegan al Reducer
    - Permiten controlar el orden de procesamiento en joins complejos

### Optimizaci√≥n de Consultas Complejas

- Estrategia de optimizaci√≥n:
    1. Descomponer la consulta en operaciones simples (filtros, joins, agrupaciones)
    2. Crear un grafo dirigido ac√≠clico (DAG) de operaciones
    3. Optimizar combinando m√∫ltiples operaciones en menos jobs
    4. Minimizar lecturas/escrituras de datos entre jobs

### Conclusi√≥n

La implementaci√≥n de operaciones complejas en MapReduce requiere pensar en t√©rminos de Map y Reduce, personalizar el comportamiento de Shuffle y Sort, y optimizar el flujo de datos para minimizar operaciones de E/S. La pr√≥xima clase abordar√° el framework Spark.

### Reflexi√≥n Final

- [ ]  Considerar si es posible implementar toda la consulta compleja presentada al final en un √∫nico job MapReduce